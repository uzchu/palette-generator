{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction \n",
    "Parse the color from the color scheme json (hexadecimal to octal rgb format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#convert # FFFFFA to  255,255,250\n",
    "def huv2num(huv):\n",
    "#     print(huv)\n",
    "    try:\n",
    "        huv = huv.replace('##','#')\n",
    "        r = int('0x'+ huv[1:3],16)\n",
    "        g = int('0x'+ huv[3:5],16)\n",
    "        b = int('0x'+ huv[5:],16)\n",
    "        return (r,g,b)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parseJson(jsonPath,colors):\n",
    "    #color_sche = []\n",
    "    color_set = []\n",
    "    with open(jsonPath,'r',encoding = 'utf-8') as load_color:\n",
    "        load_dict = json.load(load_color)\n",
    "        for key, value in load_dict.items():\n",
    "            try:\n",
    "\n",
    "                for val in value:\n",
    "                    val = huv2num(val)\n",
    "                    color_set.append(val)   \n",
    "                color = [huv2num(val) for val in value if huv2num(val)]\n",
    "                if len(color) == 5:\n",
    "                    colors.append(tuple(color))\n",
    "            except OSError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory is exist!\n"
     ]
    }
   ],
   "source": [
    "style  =  os.listdir('./palettes/')\n",
    "colors = []\n",
    "for name in style :\n",
    "    jsonPath  =  os.path.join('./palettes/', name)\n",
    "    if jsonPath.endswith('json'):\n",
    "        parseJson(jsonPath,colors)\n",
    "        \n",
    "        \n",
    "        dir_A = os.path.join('./peisenet_palettes',name.split('.')[0])\n",
    "        if os.path.exists(dir_A):\n",
    "            print(\"Directory is exist!\")\n",
    "        else:    \n",
    "            os.makedirs(dir_A)\n",
    "\n",
    "            for  i , color  in  enumerate (colors):\n",
    "                im=Image.new('RGB',(1000,1),(0,0,0)) #바탕생성 Image.new(mode,size,color)\n",
    "                draw=ImageDraw.Draw(im)\n",
    "                batch = int(1000 / 5)\n",
    "                for j, c in enumerate(color):\n",
    "                    if  j != 4 :\n",
    "                        draw.rectangle((j*batch,0,(j+1)*batch,1),fill=c)\n",
    "                    else:\n",
    "                        draw.rectangle((j*batch,0,1000,1),fill=c)\n",
    "                    im.save(dir_A + f'/{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=Image.open('./peisenet_palettes/full_colorlover/100.png')\n",
    "# img = Image.fromarray(img)\n",
    "\n",
    "new=img.resize(size=(256,1))\n",
    "new1 = new.resize(size=(256,30))\n",
    "\n",
    "plt.imshow(np.array(new))\n",
    "plt.show()\n",
    "plt.imshow(np.array(new1))\n",
    "plt.show()\n",
    "\n",
    "img.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models built \n",
    "Pix2pix's network structure is used for training. Some differences are in the input size. I use 256 1 instead of 256 256 in the image . The input becomes smaller, so I increased the number of channels. By default, the first layer uses 128. Channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f0e0de7b860>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input, Dropout\n",
    "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "import keras.backend as K\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.models import load_model\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import SVG\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights initializations\n",
    "# bias are initailized as 0\n",
    "\n",
    "# def __conv_init(a):\n",
    "#     print(\"conv_init\", a)\n",
    "#     k = RandomNormal(0, 0.02)(a) # for convolution kernel\n",
    "#     k.conv_weight = True    \n",
    "#     return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic discriminator\n",
    "conv_init = RandomNormal(0, 0.02)\n",
    "gamma_init = RandomNormal(1., 0.02) # for batch normalization\n",
    "\n",
    "\n",
    "def conv2d(f, *a, **k):\n",
    "    return Conv2D(f, kernel_initializer = conv_init, *a, **k)\n",
    "def batchnorm():\n",
    "    return BatchNormalization(momentum=0.9, axis=-1, epsilon=1.01e-5,\n",
    "                                   gamma_initializer = gamma_init)\n",
    "def BASIC_D(nc_in, nc_out, ndf, max_layers=3):\n",
    "    \"\"\"DCGAN_D(nc, ndf, max_layers=3)\n",
    "       nc: channels\n",
    "       ndf: filters of the first layer\n",
    "       max_layers: max hidden layers\n",
    "    \"\"\"    \n",
    "\n",
    "    input_a, input_b = Input(shape=(None, None, nc_in)), Input(shape=(None, None, nc_out))\n",
    "    _ = Concatenate(axis=-1)([input_a, input_b])\n",
    "    _ = conv2d(ndf, kernel_size=(1,4), strides=(1,2), padding=\"same\", name = 'First') (_)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    for layer in range(1, max_layers):        \n",
    "        out_feat = ndf * min(2**layer, 8)\n",
    "        _ = conv2d(out_feat, kernel_size=(1,4), strides=(1,2), padding=\"same\", \n",
    "                   use_bias=False, name = f'pyramid.{layer}'\n",
    "                        ) (_)\n",
    "        _ = batchnorm()(_, training=1)        \n",
    "        _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    out_feat = ndf*min(2**max_layers, 8)\n",
    "    _ = ZeroPadding2D((0,1))(_)\n",
    "    _ = conv2d(out_feat, kernel_size=(1,4),  use_bias=False, name = 'pyramid_last') (_)\n",
    "    _ = batchnorm()(_, training=1)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    # final layer\n",
    "    _ = ZeroPadding2D((0,1))(_)\n",
    "    _ = conv2d(1, kernel_size=(1,4), name = 'final'.format(out_feat, 1), \n",
    "               activation = \"sigmoid\") (_)    \n",
    "    return Model(inputs=[input_a, input_b], outputs=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNET_G(isize, nc_in=3, nc_out=3, ngf=128, fixed_input_size=True):    \n",
    "    max_nf = 8*ngf    \n",
    "    def block(x, s, nf_in, use_batchnorm=True, nf_out=None, nf_next=None):\n",
    "        # print(\"block\",x,s,nf_in, use_batchnorm, nf_out, nf_next)\n",
    "        assert s>=2 and s%2==0\n",
    "        if nf_next is None:\n",
    "            nf_next = min(nf_in*2, max_nf)\n",
    "        if nf_out is None:\n",
    "            nf_out = nf_in\n",
    "        x = conv2d(nf_next, kernel_size=(1,4), strides=(1,2), use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = f'conv_{s}') (x)\n",
    "        if s>2:\n",
    "            if use_batchnorm:\n",
    "                x = batchnorm()(x, training=1)\n",
    "            x2 = LeakyReLU(alpha=0.2)(x)\n",
    "            x2 = block(x2, s//2, nf_next)\n",
    "            x = Concatenate(axis=-1)([x, x2])            \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2DTranspose(nf_out, kernel_size=(1,4), strides=(1,2), use_bias=not use_batchnorm,\n",
    "                            kernel_initializer = conv_init,          \n",
    "                            name = f'convt.{s}')(x)        \n",
    "        x = Cropping2D(cropping=((0,0),(1,1)))(x)\n",
    "        if use_batchnorm:\n",
    "            x = batchnorm()(x, training=1)\n",
    "        if s <=8:\n",
    "            x = Dropout(0.5)(x, training=1)\n",
    "        return x\n",
    "    \n",
    "    s = isize if fixed_input_size else None\n",
    "\n",
    "    _ = inputs = Input(shape=(1, s, nc_in))        \n",
    "    _ = block(_, isize, nc_in, False, nf_out=nc_out, nf_next=ngf)\n",
    "    _ = Activation('tanh')(_)\n",
    "    return Model(inputs=inputs, outputs=[_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 6 0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "First (Conv2D)                  (None, None, None, 1 3200        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 1 0           First[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pyramid.1 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 2 1024        pyramid.1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pyramid.2 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 5 2048        pyramid.2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 5 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 5 0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pyramid_last (Conv2D)           (None, None, None, 1 2097152     zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 1 4096        pyramid_last[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, None, None, 1 0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final (Conv2D)                  (None, None, None, 1 4097        zero_padding2d_2[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 2,766,977\n",
      "Trainable params: 2,763,393\n",
      "Non-trainable params: 3,584\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 1, 256, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_256 (Conv2D)               (None, 1, 128, 128)  1664        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 1, 128, 128)  0           conv_256[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_128 (Conv2D)               (None, 1, 64, 256)   131072      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1, 64, 256)   1024        conv_128[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 1, 64, 256)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_64 (Conv2D)                (None, 1, 32, 512)   524288      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1, 32, 512)   2048        conv_64[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 1, 32, 512)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_32 (Conv2D)                (None, 1, 16, 1024)  2097152     leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1, 16, 1024)  4096        conv_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 1, 16, 1024)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 1, 8, 1024)   4194304     leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1, 8, 1024)   4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 1, 8, 1024)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 1, 4, 1024)   4194304     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 4, 1024)   4096        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 1, 4, 1024)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 1, 2, 1024)   4194304     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 2, 1024)   4096        conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 1, 2, 1024)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 1, 1, 1024)   4195328     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 1, 1024)   0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convt.2 (Conv2DTranspose)       (None, 1, 4, 1024)   4194304     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 1, 2, 1024)   0           convt.2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1, 2, 1024)   4096        cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 2, 1024)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 2, 2048)   0           batch_normalization_9[0][0]      \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 2, 2048)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.4 (Conv2DTranspose)       (None, 1, 6, 1024)   8388608     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)       (None, 1, 4, 1024)   0           convt.4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1, 4, 1024)   4096        cropping2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1, 4, 1024)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 4, 2048)   0           batch_normalization_8[0][0]      \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, 4, 2048)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.8 (Conv2DTranspose)       (None, 1, 10, 1024)  8388608     activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 1, 8, 1024)   0           convt.8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1, 8, 1024)   4096        cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1, 8, 1024)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1, 8, 2048)   0           batch_normalization_7[0][0]      \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1, 8, 2048)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.16 (Conv2DTranspose)      (None, 1, 18, 1024)  8388608     activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_4 (Cropping2D)       (None, 1, 16, 1024)  0           convt.16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 16, 1024)  4096        cropping2d_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 16, 2048)  0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1, 16, 2048)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.32 (Conv2DTranspose)      (None, 1, 34, 512)   4194304     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_5 (Cropping2D)       (None, 1, 32, 512)   0           convt.32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1, 32, 512)   2048        cropping2d_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1, 32, 1024)  0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1, 32, 1024)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.64 (Conv2DTranspose)      (None, 1, 66, 256)   1048576     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_6 (Cropping2D)       (None, 1, 64, 256)   0           convt.64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1, 64, 256)   1024        cropping2d_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1, 64, 512)   0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1, 64, 512)   0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.128 (Conv2DTranspose)     (None, 1, 130, 128)  262144      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_7 (Cropping2D)       (None, 1, 128, 128)  0           convt.128[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1, 128, 128)  512         cropping2d_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1, 128, 256)  0           conv_256[0][0]                   \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 128, 256)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.256 (Conv2DTranspose)     (None, 1, 258, 3)    3075        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_8 (Cropping2D)       (None, 1, 256, 3)    0           convt.256[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1, 256, 3)    0           cropping2d_8[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 54,440,067\n",
      "Trainable params: 54,420,355\n",
      "Non-trainable params: 19,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nc_in = 3\n",
    "nc_out = 3\n",
    "ndf = 128\n",
    "imageSize = 256\n",
    "ngf = 128\n",
    "\n",
    "netD = BASIC_D(nc_in, nc_out, ndf)\n",
    "netG = UNET_G(imageSize, nc_in, nc_out, ngf)\n",
    "\n",
    "netD.summary()\n",
    "netG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_A = netG.input\n",
    "fake_B = netG.output\n",
    "netG_generate = K.function([real_A], [fake_B])\n",
    "real_B = netD.inputs[1]\n",
    "output_D_real = netD([real_A, real_B])\n",
    "output_D_fake = netD([real_A, fake_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = lambda output, target : -K.mean(K.log(output+1e-12)*target+K.log(1-output+1e-12)*(1-target))\n",
    "\n",
    "loss_D_real = loss_fn(output_D_real, K.ones_like(output_D_real))\n",
    "loss_D_fake = loss_fn(output_D_fake, K.zeros_like(output_D_fake))\n",
    "loss_G_fake = loss_fn(output_D_fake, K.ones_like(output_D_fake))\n",
    "\n",
    "loss_L1 = K.mean(K.abs(fake_B-real_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrD = 2e-4\n",
    "lrG = 2e-4\n",
    "\n",
    "\n",
    "loss_D = loss_D_real +loss_D_fake\n",
    "training_updates = Adam(lr=lrD, beta_1=0.5).get_updates(netD.trainable_weights,[],loss_D)\n",
    "netD_train = K.function([real_A, real_B], [loss_D/2], training_updates)\n",
    "\n",
    "loss_G = loss_G_fake   + 100 * loss_L1\n",
    "training_updates = Adam(lr=lrG, beta_1=0.5).get_updates(netG.trainable_weights,[], loss_G)\n",
    "netG_train = K.function([real_A, real_B], [loss_G_fake, loss_L1], training_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reading function, generator for training \n",
    "During the generation process, the original color scheme is used as the label. I will also randomly paint a few areas of the five color areas as input for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataPath):\n",
    "    dataAB = []\n",
    "    for root,dirs,files in os.walk(dataPath):\n",
    "        for f in files:\n",
    "            if f.endswith('png'):\n",
    "                dataAB.append(os.path.join(root,f))\n",
    "    random.shuffle(dataAB)\n",
    "    \n",
    "    return dataAB[:int(len(dataAB)*0.85)], dataAB[int(len(dataAB)*0.85):]\n",
    "\n",
    "\n",
    "def read_image(img_name):\n",
    "    im = Image.open(img_name)\n",
    "    im_fake = im.copy()\n",
    "    draw_fake = ImageDraw.Draw(im_fake)\n",
    "    batch = int(im.size[0] / 5)\n",
    "    nb = random.randint(1,4)\n",
    "    index = random.sample([k for k in range(5)],nb)\n",
    "\n",
    "    for j in range(5):\n",
    "        if j in index:\n",
    "            if j != 4:\n",
    "                draw_fake.rectangle((j*batch,0,(j+1)*batch,1),fill=(0,0,0))\n",
    "            else:\n",
    "                draw_fake.rectangle((j*batch,0,im.size[0],1),fill=(0,0,0))\n",
    "\n",
    "    imgB = im\n",
    "    imgA = im_fake\n",
    "    \n",
    "    outA = np.array(imgA.resize((256,1))) / 255 * 2 - 1\n",
    "    outB = np.array(imgB.resize((256,1))) / 255 * 2 - 1\n",
    "    return outA, outB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(dataAB, batchsize, direction=0):\n",
    "    length = len(dataAB) * 10\n",
    "    epoch = i = 0\n",
    "    tmpsize = None    \n",
    "    while True:\n",
    "        size = tmpsize if tmpsize else batchsize\n",
    "        if i+size > length:\n",
    "            random.shuffle(dataAB)\n",
    "            i = 0\n",
    "            epoch+=1        \n",
    "        dataA = []\n",
    "        dataB = []\n",
    "        for j in range(i,i+size):\n",
    "            imgA,imgB = read_image(dataAB[int(j % len(dataAB))])\n",
    "            dataA.append(imgA)\n",
    "            dataB.append(imgB)\n",
    "        dataA = np.float32(dataA)\n",
    "        dataB = np.float32(dataB)\n",
    "        i+=size\n",
    "        tmpsize = yield epoch, dataA, dataB  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showX(X, epoch=0, rows=3, savefig=True):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    X = np.concatenate(X,1)\n",
    "    for i in range(rows):\n",
    "        plt.subplot(2,3,i+1)\n",
    "        plt.imshow(np.array(Image.fromarray(((X[i]+1)/2*255).clip(0,255).astype('uint8')).resize((512,100))))\n",
    "    \n",
    "    if savefig:\n",
    "        if not os.path.exists('results/'):\n",
    "            os.makedirs('results/')\n",
    "        plt.savefig(f'results/epoch_{epoch}.png')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainAB, valAB = load_data('./peisenet_palettes/full_colorlover/')\n",
    "\n",
    "train_batch = minibatch(trainAB, 6)\n",
    "_, trainA, trainB = next(train_batch)\n",
    "showX([trainA,trainB], savefig=False)\n",
    "_,a,b = train_batch.send(6)\n",
    "\n",
    "del train_batch, trainA, trainB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training \n",
    "During the training process, if the training is performed in the order of a generator and a discriminator, the result will be very poor, and the generation result is very bad, so the actual training one iteration took 3 times to generate a discriminant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netG_gen(A):\n",
    "    return np.concatenate([netG_generate([A[i:i+1]])[0] for i in range(A.shape[0])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "batchSize = 1\n",
    "niter = 3\n",
    "display_iters = 2000\n",
    "\n",
    "gen_iterations = 0\n",
    "errL1 = epoch = errG = 0\n",
    "errL1_sum = errG_sum = errD_sum = 0\n",
    "\n",
    "train_batch = minibatch(trainAB, batchSize)\n",
    "val_batch = minibatch(valAB, 6)\n",
    "current_iter = 0\n",
    "\n",
    "while epoch < niter: \n",
    "    epoch, trainA, trainB = next(train_batch)        \n",
    "    errD,  = netD_train([trainA, trainB])\n",
    "    errD_sum += errD\n",
    "    \n",
    "    errG, errL1 = netG_train([trainA, trainB])\n",
    "    errG_sum += errG\n",
    "    errL1_sum += errL1\n",
    "    \n",
    "    for i in range(3):        \n",
    "        _, trainA1, trainB1 = next(train_batch)\n",
    "        errG, errL1 = netG_train([trainA1, trainB1])\n",
    "        errG_sum += errG\n",
    "        errL1_sum += errL1\n",
    "    \n",
    "    gen_iterations += 1\n",
    "    if gen_iterations % display_iters == 0:\n",
    "        if gen_iterations % (5*display_iters) == 0:\n",
    "            clear_output()\n",
    "        print(f'[{epoch}/{niter}][{gen_iterations}] Loss_D: {errD_sum/display_iters} ' + \n",
    "              f'Loss_G: {errG_sum/(display_iters*4)} loss_L1: {errL1_sum/(display_iters*4)}')\n",
    "        \n",
    "        _, valA, valB = train_batch.send(6) \n",
    "        fakeB = netG_gen(valA)\n",
    "        showX([valA, valB, fakeB], gen_iterations)\n",
    "        \n",
    "        errL1_sum = errG_sum = errD_sum = 0\n",
    "        _, valA, valB = next(val_batch)\n",
    "        fakeB = netG_gen(valA)\n",
    "        showX([valA, valB, fakeB], gen_iterations)\n",
    "        \n",
    "    if epoch > current_iter:\n",
    "        current_iter += 1\n",
    "        \n",
    "        if not os.path.exists('weights/100L1_128channel_4gen/generator/'):\n",
    "            os.makedirs('weights/100L1_128channel_4gen/generator/')\n",
    "        if not os.path.exists('weights/100L1_128channel_4gen/discriminator/'):\n",
    "            os.makedirs('weights/100L1_128channel_4gen/discriminator/')\n",
    "        \n",
    "        netG.save(f'./weights/100L1_128channel_4gen/generator/epoch_{epoch}.hdf5')\n",
    "        netD.save(f'./weights/100L1_128channel_4gen/discriminator/epoch_{epoch}.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pj2_sam/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# Here I trained three models based on different parameters, used here as appropriate\n",
    "# generator = load_model('weights/GAN/100L1_128channel_peisenet/generator/epoch_2.hdf5')\n",
    "# generator1 = load_model('weights/GAN/100L1_128channel_4gen/generator/epoch_10.hdf5')\n",
    "# generator2 = load_model('weights/GAN/1000L1_256channel/generator/epoch_10.hdf5')\n",
    "\n",
    "generator = load_model('weights/100L1_128channel_4gen/generator/epoch_1.hdf5')\n",
    "generator1 = load_model('weights/100L1_128channel_4gen/generator/epoch_2.hdf5')\n",
    "generator2 = load_model('weights/100L1_128channel_4gen/generator/epoch_3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in generator.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACD0lEQVR4nO3cvWoUYRSA4TMzIW6SzUYRLCySwNoJ8QfEQgRBtBALbRW01yvwBmwsvAlvQMFaUPAiBAmIsKAiiaDIGmes7ETwFCdEnqed4swwh2VfBr5mGIYAAADg37T7fQMAAAAHkZgCAABIEFMAAAAJYgoAACBBTAEAACQs/O3ibHas9Ki/phni485a5ch492UlHr7eiq6te9TpeDceb72KvaGuZZv5EAsf+rJ5v63d3G0q5zVN43jK/8SZaRcvHq2Uz63e2YiIW7fv1+5tE9F9nZeOXFwaxfHpelSeIDsedXF2YzUqD62djD/FudPP6gZGxPvZidi88KR0by/euVe6sz/6Ia6vL0dfOPXwoTYurS+WzuyanzFZ/FY3MCKi24l+9WXpyHbpVGxcflq6szfuPqj9nW3b6N+8jWjqHvPIqI8rm/PSnZ20fZxfnkflP8zu6PeYXNsunBix9/lkTK4+/+PL9GUKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQEIzDMN+3wMAAMCB48sUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgIRfV8dPQ8K532UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACC0lEQVR4nO3csWpUURCA4TmbjUQiu10KC1EECwkBO0WsBHufQLDyNQS1EJc0vouVoIgWIvgCNibRQCImm0SEkORY2YnggLMEvq/dYu5lh3P598K23nsAAADwbwazvgAAAIDTSEwBAAAkiCkAAIAEMQUAAJAgpgAAABKGf/twc3Op9K/+WuuxvTuuHBlre4vx5N1KzA3qbvXyuWmsrryJo17Xsu2wx3DrpGzeb+O701Y5z87+Hwfr3+Pjsxdl82ap9166sxERP7/dK93bQYv4un0YlTe6vrsQT19dLN3b0X7EzfctTgp/NmytxWD+TN3AiBguH8T9x49K93bjw3L9Wbs9qhwZG9OFmLy9VLqz58+O4sGV63Hc657X7eg4hnv7ZfMiIn7sf4rbD1dLd3Zn61rtOTuI+PxlPlrhXW7sLMTk5YXSnR1P5+PW66U4qTzb5yJuLNa+D1q7ehR3nk/++G16MwUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgofXeZ30NAAAAp443UwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASfgEEX2NDiRTLdgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACLklEQVR4nO3coYuTcRjA8efdDibccEHUYBEMYhmn0dNosQkaBMG/wGIxGQwKoigWm0a1mS/KgWgznNxVx43pTtStOe/2s2gTwSf8jsPPpy4879jDA19eWFNKCQAAAP5Na7cfAAAAYC8SUwAAAAliCgAAIEFMAQAAJIgpAACAhIW/fTgaHar6V39NU2LrW6/myBhMF+PO6360W/W+6rHuJB72V2O71GvZZlZiYTyvNu+33oVJU3Pe/7Cz79e+x+VLm1VnLp1ox6tn+2P2o97Md+s7ce7qtN7AX0opVXc2ImJrfK3q3rZbERuDWTQVv+nsay+GK8vRtOrdod7i5zjbfxnzird2MNoXd58crTYvIuL46U7cfHS76t6uvzlV/9aO697aThyOI3ElSuzUGzr/GGX2NCLa1UYOpwfi8dvz1eZFRCx1P8X1B7eq7uzm8GTVnW21Iz5sdKre2e1xLybPlyPa9e5s9+CX6F9ciTKvd2cng16s3j9TbV5ExKjfxI0X9/74a3ozBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACChKaXs9jMAAADsOd5MAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEj4Cd1xakPLOb3eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACIUlEQVR4nO3csWpUYRCG4W9NsiYbJGARDSgmIhGijUYQBRVsvAoVTGepeAGiIJYiltZia+EFKFiJZapUFnYKIRhD3N1jZSeCU/wh+DztFnMGhoWXA6fXdV0AAAD4Nwf2+gEAAAD2IzEFAABQIKYAAAAKxBQAAECBmAIAACiY/NuPl18/bfqpv8nBwby/8yKZaNd4q12Xj7ujjJtNTMbHD2f7wY1k1G5qb7qfyRPzzeb9NnPpbq/lvP/hZvNzJ/n2ud28JOcWF/Lh0Vp2h6NmM/+Xm02SK2+fNb3bbmYqc/feNL3bY3OD3L+6nNG43apTg4nMr8ym5Udre4dm0z+/0m5gko2NLzm7eqvp3V54+bjpzY4ne1l8t5Wu4ZZLRwZ5dPN0hqN2q3bb2xmurye9hovO9JOTC+3mJdnaPJCl623/ay++etL2f3Z6IoOHn5KJdmueOjqb57fPNL3Z8XiYnR9fk7Tbszfop7/c9mY3v/dz4traH5f0ZgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAQa/rur1+BgAAgH3HmykAAIACMQUAAFAgpgAAAArEFAAAQIGYAgAAKBBTAAAABb8A3bZYQ/UBIvEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACJUlEQVR4nO3cvWoUYRSA4bM/usligkgQxIQ0KsYuCRIjWlnYCMEbsIiNWAgWXkSIndhZiQheRkjKNHb+gIWChY1GZAPqzljZieABTwg8T7vFmdk9DPvywXTatg0AAAD+TfegLwAAAOAwElMAAAAJYgoAACBBTAEAACSIKQAAgIT+3z68/GKj9FV//eEgttcfR/TqGm+5bWP3+ziasokRzdyJGD24HjGum9qZOBr9+ZNl836bXL3bqZxXvrPHhrF9417lyFjuDWJ3ajaaqLtVO/t/LT19WLq3P/rdWNt6H02n7lZPjUZx+/WrGBfObGaPx/79a6V72x0OY3h+oWxeRMSbt+9iafFW6d5eeLJZurP7P5t4dOVcjAvfQDz94VOsbDyPptcrm9nMDGN/bSGiKfx6JwfRPXu6bl5E7H3txZmrd0p3dvFZ8c72u7G59bH0mTf1bS8uvtyJplN4VjIzHc3N1Yim8P/B9EQcWZkvmxcR8fnLIOYurf/xx3QyBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACCh07btQV8DAADAoeNkCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAEDCL+hLXkNCAYWOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACJUlEQVR4nO3cvWoUYRSA4bM/uslqgkgQxIQ0KsQuCYorWlnYiOQKLAIWWoiNFxFiq5WVoOBlhLQp0okKFmkEmxCRDag7Y2Unggc8IfA87RZnZvcw7MsH02nbNgAAAPg33aO+AAAAgONITAEAACSIKQAAgAQxBQAAkCCmAAAAEvp/+/DG243SV/31h4PYXn8e0atrvNW2jZ3vk2jKJkY0C2dj/PROxKRuamfqZPQXz5XN+2169KhTOa98Z08PY/vu48qRsdobxM7MfDRRd6t29v9aefWsdG9/9Ltxb2svmk7drZ4fj+PB+3cxKZw5mT8T4ye3S/e2NzwVw6WlsnkRER8+foqV5fule3vl5Wbpzo5/NvHi5uWYFL6BeGbvS1zbeBNNr1c2s5kbxuHaUkRT+PVOD6J76ULdvIg4+NqNi7celu7s8uvanT3sd2Nz63PpM2/m20Fc3d2OplN4VjI3G83aKKIp/H8wOxUnRotl8yIi9vcHsXB9/Y8/ppMpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAmdtm2P+hoAAACOHSdTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABJ+Aeg7XkPTZvGTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACJklEQVR4nO3cu2oVYRSG4W82SYhGhWgR4gFBsRGCWIhXYR/FQowWaqE2NvZ2lh4uQbwTEVOIXVoJmGDAHFB3svdY2YngKv4QeZ52ijXzsxh4GZiu7/sAAADwbwb7fQMAAAAHkZgCAAAoEFMAAAAFYgoAAKBATAEAABRM/O3iqfnTTX/19y3DbAyXsptxs5lbc1tZvvkh3ahrNnNt4mjezl7NoOVzjibzfud4s3m/7Tx52O5gk3Rd99//nvLCyZm8eLCQvVG7R11Z3cnD15+azdtPfd833dkkubF0r+neDkd9bi3MZtxw6qHJ7Zw/sZyWx7s3OpqvO1fSNXzX7naDbAwON5uXJD/G61m8/7zp3t55fL/tzo6T22f2mu7saLSdza2PSdod7ZGZY7l08Wr6vt3Orn1P3qw0G5ckOTcxzN2nL5vu7LW7j9rubD/I4rHVjBvuz9TUbubn1pu+Z6c3k7Pvxukbfp75eWQ6ny+faTcwyZfNqVx/9uqPB+vLFAAAQIGYAgAAKBBTAAAABWIKAACgQEwBAAAUiCkAAIACMQUAAFAgpgAAAArEFAAAQIGYAgAAKBBTAAAABWIKAACgQEwBAAAUiCkAAIACMQUAAFAgpgAAAArEFAAAQIGYAgAAKBBTAAAABWIKAACgQEwBAAAUiCkAAICCru/7/b4HAACAA8eXKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFvwBA12pDpk53JwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACIElEQVR4nO3cu48NcRjH4e/M3ohLYhVsUFELleglGolCSTQqFZVYhU5Bo6PSqai29we4ZK1ohFbltthdEmftGZVOJN7ETyTP057infnlLeZzJpluGIYAAADwZ/p/fQEAAAD/IzEFAABQIKYAAAAKxBQAAECBmAIAACiY/N2Pe+b2Nv3U3+eMsjw6l/WMm81c3bWap2cW0210zWa+ndyWezuOpG95nxtTefJlttm8n75cutDuYJN0Xdf885Sj2fmMstFsnp39u1rvbJK8XLjWdG/Hm7rsv7GSYaLdzG87V/L6xKN043b/4b3pt+fuzNFMtNzb9eksLs81m5ckx/oPuXX+StO9ffP4ZtOdHbb02XL6VTLZ7ja/7ljLi+NL6cbtZr7vt2Zh5lD6tDvelfHmPBwdaDYvSU5Ofczti/NNd/bT5VNtnw+mx+nv7Ev6dmPXdq3l+dlnTZ8P3mVr7ncHm+7s6vfpLC3vbjYvSQ5vfMuD61d/ebDeTAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAo6IZh+NfXAAAA8N/xZgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAwQ95z2tDkVfTGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACOklEQVR4nO3cu2oUARSA4bO7ETExBG1CSDQIATEBEZsUBiSVkAewULuUwUtl5QMEU4jgA1hb+gqWohYKdopGI1iISVhCLrNjlU4ET3FC4PvaLc7Mzpldfgam07ZtAAAA8H+6R30AAAAAx5GYAgAASBBTAAAACWIKAAAgQUwBAAAkDP3rw8mJqdJX/W3GXvzaW479GJTN3B7fjrd33kSn6ZTN/Dk0Gi/OzEe38jybE/G6f7Zs3qH+w/t1X2zU72y3241vG+uVI4/E2PREXH+0HIODpmzm5pcf8Wr1edm8Q23blu5sRMTNhcXSvd05GMTjxQvRFL7NtTM6HL2rFyMKZ35tmljtb0WvbGLEuUEbD3br7pOIiA/bO3Hr3pPSvZ2fu1K7s7v7sbayFM2g7n/z5MjJmJo9H5VvPf7e34mn7z9Fr1N3OSdPn4qVyzNl8yIiPr/7GEt3a3f22kztzvabQbycm46Dwv1px4dj//ZsRFP4O7vbxur6XvQKr+bYQS8WtkbqBkbEpd8bcWPt2V/P0pMpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAmdtm2P+hgAAACOHU+mAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACT8AU9dckNw6B1MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACKElEQVR4nO3czYtOcRjH4e8zL8YwLEdMmaYsZMGS/AM2sjULZW0hWysrf4FSIjthM0V53YnsqKGUKIkywmTKNF7mMcfGUspdftPUdW2fxX36dfd0PufU6XVdFwAAAP7NwGpfAAAAwFokpgAAAArEFAAAQIGYAgAAKBBTAAAABUN/+/Hyg+mmn/obHuwyM7sxA712M398WMrc1RfpDbYbOtb1smdlXVoe7kiSbS0P9rdjzx42HWpn/4/Fr0t58up5s3lJsn10LCendjedmbTf2SR5MXe06d6ODnc5MTOewYaP07rP/azcXWj6CG9yfFNOTe9N/+dKs5nL7+bz8cKtZvOS5P3+qRw4e77p3t64d7Dpzq4bWsnF+1sz0Gs3tvvSZflxP2l4spMTm3Pq+L6mO7v4ej5PT99uNi9JsnNLDl251HRnr80ebrqzI8Ndzt0cy0DD/7z+p29ZuP4mLW9KdmxYnzO7ptJv+HXwL0vf8+jl22bzkmRp60SO3PnzznozBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKCg13Xdal8DAADAmuPNFAAAQIGYAgAAKBBTAAAABWIKAACgQEwBAAAUiCkAAICCX+FHbkN8/AOfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACM0lEQVR4nO3csWoUURSA4TM7ZjXZRYgWQkQQUohIMKW9CCqKplLBFxBrX0KxEVLZBAKaRt9ALaKNWggiglgEAhq0MBGJIca5FlqK4CluCHxfu8WZnTkD++/ANKWUAAAA4P/0tvsAAAAAdiIxBQAAkCCmAAAAEsQUAABAgpgCAABI2PWvD+8tXq76qr+RtsSDV4PoNfVmbn5aj48L76Jp6w0dliaOd/2oeXJ3R8REzRP7x7U3z6oOrb2zw739uDA9X3NkDEfHYnryaNR8E+d27OzKxreYX3pdceJvpZTqN8qLpZm6r1VtN6O8vBTRdNVGrnxei7mHT6Pt1fsPb3yri5Nr36Pet4wY3TeIydPHKk6MeN+uxcz121X39v6j81V39ke3GWcPXomu1Luay8urcevm42jbeju752cXh79u1P19MD4Wh04dqTgxYqxZj4s3Zqvu7MLzq1V3tmu2YuLLiSgVr+bKh9WYm31SdWcHpYmprZGqO7u/7cW5Qb/ixIi3UwfizJ27f91ZT6YAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJDSllO0+BgAAgB3HkykAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACb8AEYVnQx7KqnYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACGUlEQVR4nO3cP2sUYRDA4dm9XIKXNBFt9LQXCwn4DZIu2AmK+gWstLTS2sLaxk4QEQTTaB3ETiEgEpAgIgT/FxJJNOquhZYiOOCEwPO0V8zyMvvCj4Vr+r4PAAAA/k270w8AAACwG4kpAACABDEFAACQIKYAAAASxBQAAEDCxN9+vPXwdOlf/Q0HfdxdmY62qZu5/W4zXt9+Hs2gbuhM38SxbjIqD3cqIg5UHuxv5589Kh1qZ/+PndjZN18+x82XTwsn/tL3ffmLsrZ+tnRv9wy7uHDvUAzawrEfvkYsrUfly7K362Jxcyu6sokRM+N9MXfxROHEiCdvV2Ph3JXSvX2wvFi6s5MTXdxYPhhtUze23ehi9Hg7ovBkR99/xJFPG6V37ezh2Zi/tFA4MeLV2mrMnblaurNLK6dKd3Zq2Mf1+zPRFn62+PZ+Kz7eeRFN4T072w5ifjQqvWf3T0/FyaPjwokRq+PpOH752h8P1pcpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAlN3/c7/QwAAAC7ji9TAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABJ+AuiyY0MliWojAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACIElEQVR4nO3csWoUURiG4W9mN6uJIRoTEkUImEbsFC9AK0FEU6ggWqhEbLwFS1vtrL0BL8DCO7DRQhsbvYFgCjHFJmNhKwF/5ITg87Rb/OfsHGb3ZWC6YRgCAADA3+kPegEAAACHkZgCAAAoEFMAAAAFYgoAAKBATAEAABSM9/vww5uVpq/6mz+WXLvXZbzvqv6t02fXsvn8WXan02Yz5/q9nJvdScsvd2bUZ2n+aMOJv61cuNW1nNd1XfPXU55fXs3Q8GruTKf5+n2r2bz/zTAMTc9skjx8fLfpuR36LovftpOGOz15YjbXL69nb6/hVsejdAtz7eYl6TNktm/3e5IkX3Z+5uaDF03P7aUnm23P7Mw4x9++S/p22zyzPJ+nGxez2/DMTo6Ms7q2kKYvWu66ZDRqODD5uP0jG49eNT2zd67cb/v/oBtl2P6UljfapckoN1bn0vI2O1mczamr6xkaDu26PpPRpNm8JPn8fiu3X77+48X0ZAoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAQTcMw0GvAQAA4NDxZAoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAwS+yV0tDl5CQHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACLElEQVR4nO3cMWsUURSA0Ts7ETe7G0USIkvAEMQoATGCYiVa2FikUlAUbBQsYydKCgtB8kPsLAQLwV9hoTZrsBWbQESQJTtjYSsBL/pC4Jx2i/uYuSzzMTBV27YBAADA3+ns9wEAAAAOIjEFAACQIKYAAAASxBQAAECCmAIAAEiY2uvH96/mi37qb9CPuH6niqk9T/VvDZdOxP3nGzHZ3S02s9dp4vT0zyh5cQ/VnZgddAtO/G1+9UZVcp6d/T++jLbi2aPHxeZFRJxbORnvXm4WnRlRfmcjIrberBTd2+npJp6uD6Ouy43tLQ5jZeNhtLuTYjMP/xjHwoev0VblbunMXC8urJ0pNi8iYjT6FGcv3i66tx9fL5fd2e4knrxYLbqzR47PxqW7a9FMmmIzj3bruLw0E03Bq1s1k6jHO+UGRsT29vdYvnqv6M5+fnuq6M72+m08uNWPuuDzwbHFhbi2sR5Nwf/ZQV3F+UGn7DNtp4253rjgxIhvO+NYunLzjzvrzRQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACAhKpt2/0+AwAAwIHjzRQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACAhF9UrlhDOuYo9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACEElEQVR4nO3cv2oUYRTG4Xd2NyH7Ry2CkaRQYiLRaFAbK0stAhaiCGJhoY2W9pY24nXYeQVehZ29gjeggsRNxsJWAh7kC5Hnabc43+6eGfgxMF3f9wEAAODvDI76AAAAAMeRmAIAACgQUwAAAAViCgAAoEBMAQAAFIwO+/DDu5Wmr/qbTZPdR11Gh57q31pdP5unr15mfz5vNnMyOMjW+Eda/rgLw0GWZ0sNJ/62cu1+13Je13VeT/mfuLq9kfdvXzef23pnk+Tx7p2me9snmezttRyZ8dJiNtfX0vINspMT01y8sZP+oN3M6alpLt/caTYvST5/+piNrQdN9/bZ8ydNd3a+f5BbV1bb7s9kKduXzjWd2Xdd9keLzeYlyWA0zPjkrOnMve/zXLh+t+nOvnn4ou19thtk+duXJO2+5vj0OJv3Npre84aLi5mdWUsaXiej4UJOTZabzUuSrz/7nN++/cc/05MpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACgQUwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACgQUwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACgQUwAAAAVd3/dHfQYAAIBjx5MpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACgQUwAAAAW/AO/vR0Mg5gwbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACF0lEQVR4nO3csWoUYRSG4W83E4xZXQMq2KiQKoGkMGkSERttREHbCILiNVgKNnoZ1la2FpaKjWgVsBFtvAKxEJPMWKUTwQP+S+B52inODJwZeBn4R8MwBAAAgH8znvUNAAAAHEViCgAAoEBMAQAAFIgpAACAAjEFAABQ0P3t4trcQtOj/vb6X7lx72H6vm82c+jG6U8dazYvSaaTSbbX19I3PElxcbKQlfXzzeYdurC8PWo5z87+H7PY2c9fvubR4yfN5h0ahqHpzibJ69WVpns7v7eflzevZ9y3GzvMj7N/ZjFp+KTnTk/z4NZWDhq+n6ODPuMfP5vNS5IPux9ze+dp0719fv9O053tRsnb711aPuRofi7d2WnTnZ1OT2RrayN9w3fz5KTLpdVps3lJsvvmXa7uPGu6sy8ubrT9zu4f5NWVzYxbnprdjdMvLbabl2RpOsm1y+tNd3ZyPFldbjYuSfLt/ads3v3zd9afKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFo2EYZn0PAAAAR44/UwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKfgOWNV1DWncaTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACCUlEQVR4nO3cv2oUYRTG4Xc2q5vdxUQkVdQQzR8TSdIISirBRkQrGysLtRX0RrwFr0HwWrwCBS9AUyTRGSs7ETzFFyLP025xZtgzAz8Gvm4YhgAAAPBvRmd9AQAAAOeRmAIAACgQUwAAAAViCgAAoEBMAQAAFIz/9uPewmLTo/5O+5M8ev4qfd83mzmMR+mXJ83mJcnSfJ7D/b30DU9SnM0Xs7N/vdm839ZuHnYt53Vd53jK/8TB/k4+fnjffG7rnU2Slw8fN93bIcn05LjlyEwXL2ZrfTUtT5CdXZpn995Bhr7hzMtL2b5/t9m8JPny+VM2Np803du3r1803dkfP/sc7rbdn/lsktu31prOzGiUfjJrNy/J6MIks5VrTWeeHn3Lxs6Dpjv77tmbtu/ZbpTl71+TtLvN2co02083m77zFi5OMlu9mjR8TsbjaZavbDWblyRHp8e5sX7nj3+mL1MAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACrphGM76GgAAAM4dX6YAAAAKxBQAAECBmAIAACgQUwAAAAViCgAAoEBMAQAAFPwCFwxJQyFeyQ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACNUlEQVR4nO3cP0tWYRjH8d+xJz31PFQ4lWGpCf1By6DFoYagwVqa2pwMWoJ6A21B0NLe0lpLQ0tT0NZbCAShNUpsUMGeP01tEXQPt0ifz3qG69yciwNfDpxmNBoFAACAfzO23zcAAABwEIkpAACAAmIKAACggJgCAAAoIKYAAAAKdP52ceFQW/VXfz+He1lZXctwOKw2c9QZy/D4RLV5SXKs283y4kKGFf+keLTb5sLidLV5v52ZW25qzmuapvrvKR+v3s+g4s5+3fyWN+/fVZuXJPNzs3nx7Gn6/X61mf/LzibJk+u36u7tYJi9a/NJxXfQZDuRlZnpqu+9fjuerdmpqufs9Y7kytJ8tXlJ8mVjPRcu3a26ty9fPa+6s53DnXx6+zHNWL1jnp6azMMHtzMY1Hu/7+4Osr6xk6bi02x7bc5enq03MMn2962cv3qn6s6+vveo7s6myYfOZmoe8uSJNms35zIY1jvqTsbzOafSpN7Mbq/NwtJMtXlJsv1jO+cu3vjj4/RlCgAAoICYAgAAKCCmAAAACogpAACAAmIKAACggJgCAAAoIKYAAAAKiCkAAIACYgoAAKCAmAIAACggpgAAAAqIKQAAgAJiCgAAoICYAgAAKCCmAAAACogpAACAAmIKAACggJgCAAAoIKYAAAAKiCkAAIACYgoAAKCAmAIAACjQjEaj/b4HAACAA8eXKQAAgAJiCgAAoICYAgAAKCCmAAAACogpAACAAmIKAACgwC9AaFpDVEJzqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACK0lEQVR4nO3cPWsUARCA4dncXRZziSQKfkQDCiIkSog2WmslWIiFIIJiJyls7MXCQrAxTaz8CXb+By2tbJSApQSbKBgS79bKTgQHnBB4nvaK2d0bln1Z2KbrugAAAODfTOz1AQAAAOxHYgoAACBBTAEAACSIKQAAgAQxBQAAkND/248vV9dLP/U36Pfjzbu3MdE0ZTNnhwfiyvKZGBd+1XA43Yvzy8Oo/JBi2/Zi/viwbuDvuZdv1f2ZUb+zw3Yq7r24XzkyTh9ZiKd3HsXP0ahspp39v548fFa6t6PoxcrOh+ii7lR3em18mZ6PJupOde5wG1evn4jxuG7moG3j0PzJsnkRERsfP8fiyu3SvV1bXSvd2d3tUVx7vBjjUd3Y7c0fsfH6UzQTdZd2aqaJpUuD6MZlI6PX9uPgwmzdwIjY2hrHqQt3S3f2+YNXtTs7auLm0mYU3n7i+24T778OovAxOmamm7i4Mih9Ppic6sfRs3N1AyNi69tkHDt3449X1pspAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAlN13V7fQwAAAD7jjdTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABJ+Aa0bVUNAUNjiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACL0lEQVR4nO3coWuUcRzH8c+z3Zh6ijpQmCA4MA1ZEwSDYLQZFEGMFoMGxSxosyxt+B/YLMtWDSJisEwwyERUUHBTp7t7TDYR/IbfUF6veuH73N2X43nfA7+u7/sAAADwdya2+wIAAAD+RWIKAACgQEwBAAAUiCkAAIACMQUAAFAw+NOLy1eWmh71NzUYZOXxo0x0XbOZ+4Y7c3rhaMYNTzUc7p7MsYVhWh6kOD09mUOzw3YDf809cb7dl5mk67r//njKuYOHc+fi9WyNRs1mvnr3OrfuLzabt536vm+6s0ly9ealpnv7fTTKhYX5pr97o81BNtb2Jg0/3YlsZLp/kZZDBzumMjN3oNm8JHm5vplzl+823dsHyzea7ux4PM7skdm0PIH466c+qw9/pGv4t/NwbzJ/MunH7WZ++b6V1Tcf2w1MMjP1LWev3Wu6s09WFpvubJcu78frLUfmx/pkPjzblYa30dnc+Jy150/Ttbx33zPIqeP7m81LkrdbXc7cXvrtm/RkCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACgQUwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACgQUwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAEBB1/f9dl8DAADAP8eTKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFPwGEJ19Dd6iBFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACJ0lEQVR4nO3cvWtTYRTA4ZObNCWNlVvpYF0VBD+6uKiTtJOjUt2ki5P+CS4ObooORQUHHcWhk67Ofi0Oolsh6uDmKBTNddFNBA94SuF51gznkpy83F8Ct9d1XQAAAPBvmp2+AAAAgN1ITAEAACSIKQAAgAQxBQAAkCCmAAAAEgZ/e/H+lXulj/qbGQzi2csX0fR6ZTPb8ShWlg/FtPCphuM9/Ti2PI7KBynOzvbjwNK4buDvuScv1n2YYWf/l53Y2Xdbk7hw7UbdwF+6rivd2YiIjeu1ezucGcbjzYfRNHW/py0utHFudSWm02nZzHZxGKvnl2I6rXt7v3/bjq9bX8rmRUS8+TiJtfWN0r29e/Vm7c72B/Ho/fPSs3b/3DjWDx+NH4UH36jtx8Ez89HVfU1iMDuIdmmhbmBEfHj1Ok6v3Snd2VuXH9TeH/SH8fTtk2h6defsvvF8nD1yovT+YG/bxKmVuSg82qPpdTGa2a4bGBGfJ5/i+KXbf9xZ/0wBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASOh1XbfT1wAAALDr+GcKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQMJPUT5aQ8/xfboAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 7 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACOElEQVR4nO3cvWoUYRSA4TOzsRARLJIQMEpuQLDQJoWKl2ASUog2YqOFNpaCrTcg2GgldkogYKeFFxCQNMFNJIi/ZEFizLrZZMbKTgRP8YXg87RbnNnh8DEvA1O1bRsAAAD8m3q/LwAAAOAgElMAAAAJYgoAACBBTAEAACSIKQAAgISRv/669brsp/7qOrbWuxFVVW7kz2EcXvtSdOZK71tcX3gVI3W5lj0+NRE37l4pNu+36dGZcjc2IqqqKv55ykH3SewMd4vNW1p+F+fm7hWbFxFx9NiROHvhVDRNudv7v+xsRMSDmWtF93awPYybj+ai2WuKzfyx0Y/lZ92o6nK3tzfsx+LGWtQFz/fxybGYvTVbbF5ExObqepw/fbno3i69fFp0Z5s2Ymq0EyWH7u028X2zX3BixPvPG3H/8UJ0OuWeDyZOTsTVO2XP2kNft2N6er7ozq6+eF50Z9smYnSyjZJLu9Pbik+Lb4qesx8H/Xj44W10Cp6zYyfGY+b2fLF5ERF1bxAXz1z645/0ZgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAQtW27X5fAwAAwIHjzRQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACAhF+aI2pDxIqJNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACEUlEQVR4nO3cPWvVcBjG4Ts5rWh9GcRBdFBwcNXBxa/hXJxcnPQDKCgubq5+DEcnB3HtVHyhtqAgRWzF2qOn7WkbJzcRfMB/KVzXmuFJwkPIj0C6YRgCAADAv+kP+gQAAAAOIzEFAABQIKYAAAAKxBQAAECBmAIAACiY+evR8cu2v/rr+4w/vE+6rt3IrWmOrXxuOvPd+rfcevYiM327lj1/8Wxu35tvNu+362dutLuxSfudPXEqXXel6Uj+r2EY2u5skt3pp6Z7OzN7NI/vPsxoNGo2czQMObm332xekmxNtrOy/DFdw+f70HeZHpltNi9JLl27kDv3nzTd2/W1haY723V9NtdWk7S7zOlkki9LS0335/vmJK8WVtI3nLm3P2S8vddsXpJcPTeX+QdPm+7seGOx6c6O+lEWl9803Z/9nz8yefu66Tvt7tedbDxfTfp2M3f6PqtzR5rNS5LTl4/n5qM/P2d9mQIAACgQUwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACgQUwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACgQUwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQ0A3DcNDnAAAAcOj4MgUAAFAgpgAAAArEFAAAQIGYAgAAKBBTAAAABWIKAACg4Bc2n11D0d7dGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACE0lEQVR4nO3czYtNARjH8efcRlHKhoskbOwlC2Rha+clZkHZ2LCysCEsLPwltqTI8i7Gwh+gJLcZb+Vl3JrRaOa+uMfKTspTnmnq89nexXM6/TbfTt2mbdsAAADg33TW+wEAAAA2IjEFAACQIKYAAAASxBQAAECCmAIAAEiY+euvK3O1f/XX6cTKu35E09SdXBvHlvkvpTdfD5biyuNezHTqWnbP/l1x9falsnu/Hdt+tu7FRkTTNOV/TznsP4jReFJ2z2b/r+rNRkT0rt0t3e1kdRJH75+I9mfh2R/DmL78ULrbt9+W486j56W73XFgd5y7d7nsXkTEqP8xTh2eLd3twqte6WbbaGLbZLHyZDTDUWx6/7l0s/OD73HjyYvSze7c242L18+X3YuI2Ly4FsePnCnd7KeHz2o3O21i68GliMqrq+OIN19LN7swWI6bT+dKN9vd143ZWxfK7kVEdAbTOHno9B9frC9TAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABKatm3X+xkAAAA2HF+mAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACT8Agh2ZkMOKzS/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACNklEQVR4nO3cv2oUURjG4Xd2k2Yhl2AnRi0UBBuvwEvwArwGbQXBJpWFhWBQMJWVaCEEtBDECGohKKKYZImGSND8WUKyySZjZSeCpzgh+DztFt/M8HHYHwPTtG0bAAAA/k3nsC8AAADgKBJTAAAABcQUAABAATEFAABQQEwBAAAUGPvbj4PVJ1U/9Tfe7eTxh8V0mqbazM2tvbx8/73qzK0fG3n36HmaTr2W3R+NMthcqzbvt8V+v96DTdI0TfXPUz58NZ3R3qjavC8f+7l6+Ua1eUnS6/VyYvJ0an7983/Z2SR5e/dm1b1tdw8ycelYclBvbLM+zPjTb0mn3uNdGezk3pv5dCue76PhMD+XvlablyTnL5zKlanbVfd24fVM1Z0da5K57f3UvMmJ5iDnxoapeaP95fVcv/UsY916/w/2RvtZ3RhUm5ckF88ez7Xpmao7u/zift2dTTI33q26s73tnUx+nk9b8cxbWtvO1OyndCue7bs7w6wsLFeblyRnJk/mzuyDP96kN1MAAAAFxBQAAEABMQUAAFBATAEAABQQUwAAAAXEFAAAQAExBQAAUEBMAQAAFBBTAAAABcQUAABAATEFAABQQEwBAAAUEFMAAAAFxBQAAEABMQUAAFBATAEAABQQUwAAAAXEFAAAQAExBQAAUEBMAQAAFBBTAAAABcQUAABAgaZt28O+BgAAgCPHmykAAIACYgoAAKCAmAIAACggpgAAAAqIKQAAgAJiCgAAoMAvas16Q+0k0foAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACIklEQVR4nO3cMWtTYRTH4f9NrbQdBDt0EBQcVOjm6u7gt3BxUlD8Eg6uFsFdkLrpoLMggqOiBRVsFQettdrSWkya69RNBA/4lsLzrBnOzc1J4JcLb9f3fQAAAPg3g/2+AAAAgINITAEAABSIKQAAgAIxBQAAUCCmAAAACg797cXN1UdNj/qbnBjk4evlDLqu2cyNrWGevfrcdObW2o+8ePAk3aBdy+6ORtncWG82b8/yykq7G5uk6zrHU/4HMzMzOX1mPi1P/9ze3s7bN0vN5u3p+77pzibJ7ZvXm+7tqE/OzR5Oy6F9kl9d2//vVrdGWXy5nkHDT3R2sJvzU5vtBiZZOzmXi1cXmu7t04XLTXd2PO5z4tiRtDyAeNgna8MuLW/spy+buXX3eSYm2n1XuumpTJ463mxeklyYn86Va3ea7uy7+zea7mzXDbKx+iFpuEE7o2Hef/+allv7bTt5vDRu+js7uTPO3Mef7QYmOTt/NJcW7/3xXXoyBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKCg6/t+v68BAADgwPFkCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAEDBb+z/Z0Om3gW0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACLUlEQVR4nO3cvWoUYRSA4TObjSJiLCSiggiihWAteANegNoJASsLsRFsvAIR1MJGwc5exB+ElDY2ASFiGoskKAENS0iWyJL9GSs7ETzFCZHnabc4M8th2HcHvqZt2wAAAODfdHb7AgAAAPYiMQUAAJAgpgAAABLEFAAAQIKYAgAASOj+7cP++rvSo/6mpzrxemklOk1TNnNrexgfPn8vnbnd24zFV++j6dS17Hg0iv7WRtm831ZWV+u+2Ihomua/P55y9uSJuHrnRkzG47KZ61/X4sXDZ2XzdlPbtqU7GxHx+OZc6d5ORuM4e/FcVJ7m2msn8XY0KP0Hb3ZnFJfXejEpfL5P7+/GkeOHy+ZFRCwMhjF361Hp3j6/f7t2ZydtnDp9NCoPIO4NhvFmufb3wbFDB+L6hTMxntTdaL8/iIWPy2XzIiJmOoO4dvdp6c5+evmgdGc70cSXnc2ovMmNYRPzP6aiUzi0u/EzZuaXonLo7MFuXDlf+5z9tm86Lt178seb9GYKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQELTtu1uXwMAAMCe480UAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgIRfuB9tQyZTwLYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACTklEQVR4nO3cP2tTURjA4fcmrabqUGnRQdq0iw6u4uwkCGILgkUQOklBHJxKUdD6Z3IVXRQ/gTqIg4vg4qSLX8DaCi6lpdAl0ibHRTcRfIcjhedZM7z3JCcn/HLhNqWUAAAA4N+0/vcFAAAA7EViCgAAIEFMAQAAJIgpAACABDEFAACQMPS3FxeX71Z91F9rZF+sLT2PpqnXeJP7h+LmsdHoV1xpuxmPQ0MzETGoN/T4TpTHm/Xm/dKauNXUnNc0TfXHU15pTsQg6o3djF68LWvV5kVEnOp04+PUcpSyW23mp95qnF59UG3eb6WUqns2ImLu2fWq+3bQGY7pe2+itOudtaNTR+LM/csx2O1Xm3lwvR0nXx2IUvFvw62xnXh/ru5Zu722EVfnH1bdt5ee3qh71naGY3D7RUTFPTvRPRyLd85Gf7feb3Wz3on2y25Eq97b2xv/EV9nvlebFxGx9WUjZheeVN2zswtzVfdsGR6KkdcfIlr1lnl0rBPzFyajP6i31M7WWEy/Ox+lVe970uv2YmVppdq8iIhvn7fj4rVHf/ww3ZkCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkNCUUv73NQAAAOw57kwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASPgJVlJlQ1o+1XoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACJUlEQVR4nO3cPWsUcRDA4dm9kFwwkAiiqPEFxChYqL2NipWgpYVaB1KpoMZooWg+gkUaaz+IjY1obSMpRFTUkGtMcrc2liI44ITA87RbzO4y/OHHwjZd1wUAAAD/pt3uGwAAANiJxBQAAECCmAIAAEgQUwAAAAliCgAAIGHsbxfvPX5S+qu/dnI8VhdfRNPUNd7hibFYOjgTw8In7TV7YmrsakSM6obObUb3/FvdvN/aQw+bynnVO9ufnIyni/crR8bZial4NXs6Ngr/xGln/6/Ly3dL93YUEceG41E59MBgPebfvI5h4fke/X3RHr0R0Q3LRrazvejf2lU2LyLi/YfVOHNyvnRvrzy4XbqzGz+34trC+RiN6sbOfPwcF1ZexqjXK5sZw93RDi5F5VnbHRnGcGm9bF5ExI/v/Th+6k7pzt589qh0Z7eiiYvNWuk5Oz0YxLl3b2PU1L3a3sbemPp0PaKpO2ebE5vRrnwpmxcRsfZ1OvbPLfzxxfoyBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACCh6bpuu+8BAABgx/FlCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAEDCL0POXUPk3PU+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACH0lEQVR4nO3cv0tVcRjH8c+53h+IYg5KlCgG0WZEQTT3BxS0RVNLEg1tFdag0NDYUlO0B41B/0OL0OwkNkk/BhtE7bY0RtADfUN4vdY7POfLfTicNwdONx6PAwAAwN/p/e8LAAAAOI7EFAAAQIGYAgAAKBBTAAAABWIKAACgoP+nHx+sbzT91F9vcpjtR6/Tde0ab2nUz9rCbI4annSim8t0/3qSH+2GnjvI+MWXdvN+6S0+7lrOs7P/xub+Xq5++thuYJJL5xfy4d3dpjOT9jubJDeftd3bjIbpv3yT9Bru7WCQh/NzOWr4Bdm90/PZXL2R7qjdvXZmOrm80vbv3NrazcrKatO9vbX2pOkhu8Eg39++b7qzy8OJbJycyWHDkx4uzeXb2rWk4c72u/2c6O80m5ckXz9P5uyF+0139vbaetvng9Ew289fpWu4s2dGgzxdnM9hw/vs+NRMDu5cabuzU73MroyazUuS3Z2pLF+899ud9WYKAACgQEwBAAAUiCkAAIACMQUAAFAgpgAAAArEFAAAQIGYAgAAKBBTAAAABWIKAACgQEwBAAAUiCkAAIACMQUAAFAgpgAAAArEFAAAQIGYAgAAKBBTAAAABWIKAACgQEwBAAAUiCkAAIACMQUAAFAgpgAAAArEFAAAQEE3Ho//9zUAAAAcO95MAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACj4CRUAVENqBVsxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.shuffle(colors)\n",
    "# color = colors[100]\n",
    "\n",
    "for i,color in enumerate(colors[:10]):\n",
    "    print(f'Processing {i} ... ')\n",
    "\n",
    "    # color = [(212,123,80) for _ in range(8)]\n",
    "    batch = int(256 / 5)\n",
    "    for _ in range(3):\n",
    "        img = Image.new(\"RGB\",(256,1),(0,0,0))\n",
    "        im = np.array(img)\n",
    "        im_fake = np.array(img)\n",
    "        nb = random.randint(1,4)\n",
    "        index = random.sample([k for k in range(5)],nb)\n",
    "        for j, c in enumerate(color):\n",
    "            if j not in index:\n",
    "                if j == len(color)-1:\n",
    "                    im_fake[:,j*batch:,:] = c\n",
    "                else:\n",
    "                    im_fake[:,j*batch:(j+1)*batch,:] = c\n",
    "\n",
    "            if j == len(color)-1:\n",
    "                im[:,j*batch:,:] = c\n",
    "            else:\n",
    "                im[:,j*batch:(j+1)*batch,:] = c\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(15,15))\n",
    "\n",
    "        plt.subplot(1,5,1)\n",
    "        plt.imshow(np.array(Image.fromarray(im).resize((512,80))))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,5,2)\n",
    "        plt.imshow(np.array(Image.fromarray(im_fake).resize((512,80))))\n",
    "        plt.axis('off')\n",
    "\n",
    "        result = generator.predict(np.expand_dims(im_fake / 255 * 2 - 1,0))[0]\n",
    "        result1 = generator1.predict(np.expand_dims(im_fake / 255 * 2 - 1,0))[0]\n",
    "        result2 = generator2.predict(np.expand_dims(im_fake / 255 * 2 - 1,0))[0]\n",
    "        \n",
    "        for i in range(5):\n",
    "            result[:,i*batch:(i+1)*batch,:] = np.mean(result[:,i*batch:(i+1)*batch,:],1)[0]\n",
    "            result1[:,i*batch:(i+1)*batch,:] = np.mean(result1[:,i*batch:(i+1)*batch,:],1)[0]\n",
    "            result2[:,i*batch:(i+1)*batch,:] = np.mean(result2[:,i*batch:(i+1)*batch,:],1)[0]\n",
    "            \n",
    "        plt.subplot(1,5,3)\n",
    "        res = np.array(Image.fromarray(((result+1)/2*255).clip(0,255).astype('uint8')).resize((512,80)))\n",
    "        plt.imshow(res)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,5,4)\n",
    "        res1 = np.array(Image.fromarray(((result1+1)/2*255).clip(0,255).astype('uint8')).resize((512,80)))\n",
    "        plt.imshow(res1)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,5,5)\n",
    "        res2 = np.array(Image.fromarray(((result2+1)/2*255).clip(0,255).astype('uint8')).resize((512,80)))\n",
    "        plt.imshow(res2)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
