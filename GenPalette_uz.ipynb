{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction \n",
    "Parse the color from the color scheme json (hexadecimal to octal rgb format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#convert # FFFFFA to  255,255,250\n",
    "def huv2num(huv):\n",
    "#     print(huv)\n",
    "    try:\n",
    "        huv = huv.replace('##','#')\n",
    "        r = int('0x'+ huv[1:3],16)\n",
    "        g = int('0x'+ huv[3:5],16)\n",
    "        b = int('0x'+ huv[5:],16)\n",
    "        return (r,g,b)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parseJson(jsonPath,colors):\n",
    "    #color_sche = []\n",
    "    color_set = []\n",
    "    with open(jsonPath,'r',encoding = 'utf-8') as load_color:\n",
    "        load_dict = json.load(load_color)\n",
    "        for key, value in load_dict.items():\n",
    "            try:\n",
    "\n",
    "                for val in value:\n",
    "                    val = huv2num(val)\n",
    "                    color_set.append(val)   \n",
    "                color = [huv2num(val) for val in value if huv2num(val)]\n",
    "                if len(color) == 5:\n",
    "                    colors.append(tuple(color))\n",
    "            except OSError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#최종\n",
    "import os\n",
    "import json\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#convert # FFFFFA to  255,255,250\n",
    "def huv2num(huv):\n",
    "#     print(huv)\n",
    "    try:\n",
    "        huv = huv.replace('##','#')\n",
    "        r = int('0x'+ huv[1:3],16)\n",
    "        g = int('0x'+ huv[3:5],16)\n",
    "        b = int('0x'+ huv[5:],16)\n",
    "        return (r,g,b)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parseJson(jsonPath,colors):\n",
    "    #color_sche = []\n",
    "    color_set = []\n",
    "    with open(jsonPath,'r',encoding = 'utf-8') as load_color:\n",
    "        load_dict = json.load(load_color)\n",
    "        for idx, values in enumerate(load_dict.items()):\n",
    "            try:\n",
    "                \n",
    "                for value in values[1:3]:\n",
    "                    for vals in value:\n",
    "                        for val in vals:\n",
    "                            val = huv2num(val)\n",
    "                    color_set.append(val)   \n",
    "                color = [huv2num(val) for val in value if huv2num(val)]\n",
    "                if len(color) == 5:\n",
    "                    colors.append(tuple(color))\n",
    "\n",
    "\n",
    "            except OSError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#convert # FFFFFA to  255,255,250\n",
    "def huv2num(huv):\n",
    "#     print(huv)\n",
    "    try:\n",
    "        huv = huv.replace('##','#')\n",
    "        r = int('0x'+ huv[1:3],16)\n",
    "        g = int('0x'+ huv[3:5],16)\n",
    "        b = int('0x'+ huv[5:],16)\n",
    "        return (r,g,b)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parseJson(jsonPath,colors):\n",
    "    #color_sche = []\n",
    "    color_set = []\n",
    "    with open(jsonPath,'r',encoding = 'utf-8') as load_color:\n",
    "        load_dict = json.load(load_color)\n",
    "        for idx, value in enumerate(load_dict.items()):\n",
    "            try:\n",
    "                if idx==3:\n",
    "                    print(value[1:2])\n",
    "\n",
    "\n",
    "            except OSError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[[39, 38, 34], [58, 50, 42], [79, 69, 59], [128, 110, 97], [103, 89, 78], [169, 157, 145], [151, 131, 116], [190, 176, 163], [207, 198, 187], [243, 239, 230]], [[41, 40, 35], [60, 45, 36], [78, 56, 44], [181, 161, 159], [104, 71, 53], [197, 176, 171], [166, 144, 140], [128, 94, 76], [150, 124, 112], [247, 237, 218]]],)\n"
     ]
    }
   ],
   "source": [
    "style  =  os.listdir('./json/')\n",
    "colors = []\n",
    "for name in style :\n",
    "    jsonPath  =  os.path.join('./json/', name)\n",
    "    if jsonPath.endswith('json'):\n",
    "        parseJson(jsonPath,colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory is exist!\n"
     ]
    }
   ],
   "source": [
    "style  =  os.listdir('./palettes/')\n",
    "colors = []\n",
    "for name in style :\n",
    "    jsonPath  =  os.path.join('./palettes/', name)\n",
    "    if jsonPath.endswith('json'):\n",
    "        parseJson(jsonPath,colors)\n",
    "        \n",
    "        \n",
    "        dir_A = os.path.join('./peisenet_palettes',name.split('.')[0])\n",
    "        if os.path.exists(dir_A):\n",
    "            print(\"Directory is exist!\")\n",
    "        else:    \n",
    "            os.makedirs(dir_A)\n",
    "\n",
    "            for  i , color  in  enumerate (colors):\n",
    "                im=Image.new('RGB',(1000,1),(0,0,0)) #바탕생성 Image.new(mode,size,color)\n",
    "                draw=ImageDraw.Draw(im)\n",
    "                batch = int(1000 / 5)\n",
    "                for j, c in enumerate(color):\n",
    "                    if  j != 4 :\n",
    "                        draw.rectangle((j*batch,0,(j+1)*batch,1),fill=c)\n",
    "                    else:\n",
    "                        draw.rectangle((j*batch,0,1000,1),fill=c)\n",
    "                    im.save(dir_A + f'/{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=Image.open('./peisenet_palettes/full_colorlover/12.png')\n",
    "# img = Image.fromarray(img)\n",
    "\n",
    "new=img.resize(size=(256,1))\n",
    "new1 = new.resize(size=(256,30))\n",
    "\n",
    "plt.imshow(np.array(new))\n",
    "plt.show()\n",
    "plt.imshow(np.array(new1))\n",
    "plt.show()\n",
    "\n",
    "img.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models built \n",
    "Pix2pix's network structure is used for training. Some differences are in the input size. I use 256 1 instead of 256 256 in the image . The input becomes smaller, so I increased the number of channels. By default, the first layer uses 128. Channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lab13/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f5e3b007a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input, Dropout\n",
    "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "import keras.backend as K\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.models import load_model\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import SVG\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights initializations\n",
    "# bias are initailized as 0\n",
    "\n",
    "# def __conv_init(a):\n",
    "#     print(\"conv_init\", a)\n",
    "#     k = RandomNormal(0, 0.02)(a) # for convolution kernel\n",
    "#     k.conv_weight = True    \n",
    "#     return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic discriminator\n",
    "conv_init = RandomNormal(0, 0.02)\n",
    "gamma_init = RandomNormal(1., 0.02) # for batch normalization\n",
    "\n",
    "\n",
    "def conv2d(f, *a, **k):\n",
    "    return Conv2D(f, kernel_initializer = conv_init, *a, **k)\n",
    "def batchnorm():\n",
    "    return BatchNormalization(momentum=0.9, axis=-1, epsilon=1.01e-5,\n",
    "                                   gamma_initializer = gamma_init)\n",
    "def BASIC_D(nc_in, nc_out, ndf, max_layers=3):\n",
    "    \"\"\"DCGAN_D(nc, ndf, max_layers=3)\n",
    "       nc: channels\n",
    "       ndf: filters of the first layer\n",
    "       max_layers: max hidden layers\n",
    "    \"\"\"    \n",
    "\n",
    "    input_a, input_b = Input(shape=(None, None, nc_in)), Input(shape=(None, None, nc_out))\n",
    "    _ = Concatenate(axis=-1)([input_a, input_b])\n",
    "    _ = conv2d(ndf, kernel_size=(1,4), strides=(1,2), padding=\"same\", name = 'First') (_)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    for layer in range(1, max_layers):        \n",
    "        out_feat = ndf * min(2**layer, 8)\n",
    "        _ = conv2d(out_feat, kernel_size=(1,4), strides=(1,2), padding=\"same\", \n",
    "                   use_bias=False, name = f'pyramid.{layer}'\n",
    "                        ) (_)\n",
    "        _ = batchnorm()(_, training=1)        \n",
    "        _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    out_feat = ndf*min(2**max_layers, 8)\n",
    "    _ = ZeroPadding2D((0,1))(_)\n",
    "    _ = conv2d(out_feat, kernel_size=(1,4),  use_bias=False, name = 'pyramid_last') (_)\n",
    "    _ = batchnorm()(_, training=1)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    # final layer\n",
    "    _ = ZeroPadding2D((0,1))(_)\n",
    "    _ = conv2d(1, kernel_size=(1,4), name = 'final'.format(out_feat, 1), \n",
    "               activation = \"sigmoid\") (_)    \n",
    "    return Model(inputs=[input_a, input_b], outputs=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNET_G(isize, nc_in=3, nc_out=3, ngf=128, fixed_input_size=True):    \n",
    "    max_nf = 8*ngf    \n",
    "    def block(x, s, nf_in, use_batchnorm=True, nf_out=None, nf_next=None):\n",
    "        # print(\"block\",x,s,nf_in, use_batchnorm, nf_out, nf_next)\n",
    "        assert s>=2 and s%2==0\n",
    "        if nf_next is None:\n",
    "            nf_next = min(nf_in*2, max_nf)\n",
    "        if nf_out is None:\n",
    "            nf_out = nf_in\n",
    "        x = conv2d(nf_next, kernel_size=(1,4), strides=(1,2), use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = f'conv_{s}') (x)\n",
    "        if s>2:\n",
    "            if use_batchnorm:\n",
    "                x = batchnorm()(x, training=1)\n",
    "            x2 = LeakyReLU(alpha=0.2)(x)\n",
    "            x2 = block(x2, s//2, nf_next)\n",
    "            x = Concatenate(axis=-1)([x, x2])            \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2DTranspose(nf_out, kernel_size=(1,4), strides=(1,2), use_bias=not use_batchnorm,\n",
    "                            kernel_initializer = conv_init,          \n",
    "                            name = f'convt.{s}')(x)        \n",
    "        x = Cropping2D(cropping=((0,0),(1,1)))(x)\n",
    "        if use_batchnorm:\n",
    "            x = batchnorm()(x, training=1)\n",
    "        if s <=8:\n",
    "            x = Dropout(0.5)(x, training=1)\n",
    "        return x\n",
    "    \n",
    "    s = isize if fixed_input_size else None\n",
    "\n",
    "    _ = inputs = Input(shape=(1, s, nc_in))        \n",
    "    _ = block(_, isize, nc_in, False, nf_out=nc_out, nf_next=ngf)\n",
    "    _ = Activation('tanh')(_)\n",
    "    return Model(inputs=inputs, outputs=[_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lab13/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lab13/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lab13/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lab13/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lab13/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lab13/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lab13/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 6 0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "First (Conv2D)                  (None, None, None, 1 3200        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 1 0           First[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pyramid.1 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 2 1024        pyramid.1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pyramid.2 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 5 2048        pyramid.2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 5 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 5 0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pyramid_last (Conv2D)           (None, None, None, 1 2097152     zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 1 4096        pyramid_last[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, None, None, 1 0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final (Conv2D)                  (None, None, None, 1 4097        zero_padding2d_2[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 2,766,977\n",
      "Trainable params: 2,763,393\n",
      "Non-trainable params: 3,584\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 1, 256, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_256 (Conv2D)               (None, 1, 128, 128)  1664        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 1, 128, 128)  0           conv_256[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_128 (Conv2D)               (None, 1, 64, 256)   131072      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1, 64, 256)   1024        conv_128[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 1, 64, 256)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_64 (Conv2D)                (None, 1, 32, 512)   524288      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1, 32, 512)   2048        conv_64[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 1, 32, 512)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_32 (Conv2D)                (None, 1, 16, 1024)  2097152     leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1, 16, 1024)  4096        conv_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 1, 16, 1024)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 1, 8, 1024)   4194304     leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1, 8, 1024)   4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 1, 8, 1024)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 1, 4, 1024)   4194304     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 4, 1024)   4096        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 1, 4, 1024)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 1, 2, 1024)   4194304     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 2, 1024)   4096        conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 1, 2, 1024)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 1, 1, 1024)   4195328     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 1, 1024)   0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convt.2 (Conv2DTranspose)       (None, 1, 4, 1024)   4194304     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 1, 2, 1024)   0           convt.2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1, 2, 1024)   4096        cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 2, 1024)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 2, 2048)   0           batch_normalization_9[0][0]      \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 2, 2048)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.4 (Conv2DTranspose)       (None, 1, 6, 1024)   8388608     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)       (None, 1, 4, 1024)   0           convt.4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1, 4, 1024)   4096        cropping2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1, 4, 1024)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 4, 2048)   0           batch_normalization_8[0][0]      \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, 4, 2048)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.8 (Conv2DTranspose)       (None, 1, 10, 1024)  8388608     activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 1, 8, 1024)   0           convt.8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1, 8, 1024)   4096        cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1, 8, 1024)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1, 8, 2048)   0           batch_normalization_7[0][0]      \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1, 8, 2048)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.16 (Conv2DTranspose)      (None, 1, 18, 1024)  8388608     activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_4 (Cropping2D)       (None, 1, 16, 1024)  0           convt.16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 16, 1024)  4096        cropping2d_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 16, 2048)  0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1, 16, 2048)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.32 (Conv2DTranspose)      (None, 1, 34, 512)   4194304     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_5 (Cropping2D)       (None, 1, 32, 512)   0           convt.32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1, 32, 512)   2048        cropping2d_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1, 32, 1024)  0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1, 32, 1024)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.64 (Conv2DTranspose)      (None, 1, 66, 256)   1048576     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_6 (Cropping2D)       (None, 1, 64, 256)   0           convt.64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1, 64, 256)   1024        cropping2d_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1, 64, 512)   0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1, 64, 512)   0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.128 (Conv2DTranspose)     (None, 1, 130, 128)  262144      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_7 (Cropping2D)       (None, 1, 128, 128)  0           convt.128[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1, 128, 128)  512         cropping2d_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1, 128, 256)  0           conv_256[0][0]                   \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 128, 256)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.256 (Conv2DTranspose)     (None, 1, 258, 3)    3075        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_8 (Cropping2D)       (None, 1, 256, 3)    0           convt.256[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1, 256, 3)    0           cropping2d_8[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 54,440,067\n",
      "Trainable params: 54,420,355\n",
      "Non-trainable params: 19,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nc_in = 3\n",
    "nc_out = 3\n",
    "ndf = 128\n",
    "imageSize = 256\n",
    "ngf = 128\n",
    "\n",
    "netD = BASIC_D(nc_in, nc_out, ndf)\n",
    "netG = UNET_G(imageSize, nc_in, nc_out, ngf)\n",
    "\n",
    "netD.summary()\n",
    "netG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_A = netG.input\n",
    "fake_B = netG.output\n",
    "netG_generate = K.function([real_A], [fake_B])\n",
    "real_B = netD.inputs[1]\n",
    "output_D_real = netD([real_A, real_B])\n",
    "output_D_fake = netD([real_A, fake_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = lambda output, target : -K.mean(K.log(output+1e-12)*target+K.log(1-output+1e-12)*(1-target))\n",
    "\n",
    "loss_D_real = loss_fn(output_D_real, K.ones_like(output_D_real))\n",
    "loss_D_fake = loss_fn(output_D_fake, K.zeros_like(output_D_fake))\n",
    "loss_G_fake = loss_fn(output_D_fake, K.ones_like(output_D_fake))\n",
    "\n",
    "loss_L1 = K.mean(K.abs(fake_B-real_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrD = 2e-4\n",
    "lrG = 2e-4\n",
    "\n",
    "\n",
    "loss_D = loss_D_real +loss_D_fake\n",
    "training_updates = Adam(lr=lrD, beta_1=0.5).get_updates(netD.trainable_weights,[],loss_D)\n",
    "netD_train = K.function([real_A, real_B], [loss_D/2], training_updates)\n",
    "\n",
    "loss_G = loss_G_fake   + 100 * loss_L1\n",
    "training_updates = Adam(lr=lrG, beta_1=0.5).get_updates(netG.trainable_weights,[], loss_G)\n",
    "netG_train = K.function([real_A, real_B], [loss_G_fake, loss_L1], training_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reading function, generator for training \n",
    "During the generation process, the original color scheme is used as the label. I will also randomly paint a few areas of the five color areas as input for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataPath):\n",
    "    dataAB = []\n",
    "    for root,dirs,files in os.walk(dataPath):\n",
    "        for f in files:\n",
    "            if f.endswith('png'):\n",
    "                dataAB.append(os.path.join(root,f))\n",
    "    random.shuffle(dataAB)\n",
    "    \n",
    "    return dataAB[:int(len(dataAB)*0.85)], dataAB[int(len(dataAB)*0.85):]\n",
    "\n",
    "\n",
    "def read_image(img_name):\n",
    "    im = Image.open(img_name)\n",
    "    im_fake = im.copy()\n",
    "    draw_fake = ImageDraw.Draw(im_fake)\n",
    "    batch = int(im.size[0] / 5)\n",
    "    nb = random.randint(1,4)\n",
    "    index = random.sample([k for k in range(5)],nb)\n",
    "\n",
    "    for j in range(5):\n",
    "        if j in index:\n",
    "            if j != 4:\n",
    "                draw_fake.rectangle((j*batch,0,(j+1)*batch,1),fill=(0,0,0))\n",
    "            else:\n",
    "                draw_fake.rectangle((j*batch,0,im.size[0],1),fill=(0,0,0))\n",
    "\n",
    "    imgB = im\n",
    "    imgA = im_fake\n",
    "    \n",
    "    outA = np.array(imgA.resize((256,1))) / 255 * 2 - 1\n",
    "    outB = np.array(imgB.resize((256,1))) / 255 * 2 - 1\n",
    "    return outA, outB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(dataAB, batchsize, direction=0):\n",
    "    length = len(dataAB) * 10\n",
    "    epoch = i = 0\n",
    "    tmpsize = None    \n",
    "    while True:\n",
    "        size = tmpsize if tmpsize else batchsize\n",
    "        if i+size > length:\n",
    "            random.shuffle(dataAB)\n",
    "            i = 0\n",
    "            epoch+=1        \n",
    "        dataA = []\n",
    "        dataB = []\n",
    "        for j in range(i,i+size):\n",
    "            imgA,imgB = read_image(dataAB[int(j % len(dataAB))])\n",
    "            dataA.append(imgA)\n",
    "            dataB.append(imgB)\n",
    "        dataA = np.float32(dataA)\n",
    "        dataB = np.float32(dataB)\n",
    "        i+=size\n",
    "        tmpsize = yield epoch, dataA, dataB  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showX(X, epoch=0, rows=3, savefig=True):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    X = np.concatenate(X,1)\n",
    "    for i in range(rows):\n",
    "        plt.subplot(2,3,i+1)\n",
    "        plt.imshow(np.array(Image.fromarray(((X[i]+1)/2*255).clip(0,255).astype('uint8')).resize((512,100))))\n",
    "    \n",
    "    if savefig:\n",
    "        if not os.path.exists('results/'):\n",
    "            os.makedirs('results/')\n",
    "        plt.savefig(f'results/epoch_{epoch}.png')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainAB, valAB = load_data('./peisenet_palettes/full_colorlover/')\n",
    "\n",
    "train_batch = minibatch(trainAB, 6)\n",
    "_, trainA, trainB = next(train_batch)\n",
    "showX([trainA,trainB], savefig=False)\n",
    "_,a,b = train_batch.send(6)\n",
    "\n",
    "del train_batch, trainA, trainB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training \n",
    "During the training process, if the training is performed in the order of a generator and a discriminator, the result will be very poor, and the generation result is very bad, so the actual training one iteration took 3 times to generate a discriminant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netG_gen(A):\n",
    "    return np.concatenate([netG_generate([A[i:i+1]])[0] for i in range(A.shape[0])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "batchSize = 1\n",
    "niter = 3\n",
    "display_iters = 2000\n",
    "\n",
    "gen_iterations = 0\n",
    "errL1 = epoch = errG = 0\n",
    "errL1_sum = errG_sum = errD_sum = 0\n",
    "\n",
    "train_batch = minibatch(trainAB, batchSize)\n",
    "val_batch = minibatch(valAB, 6)\n",
    "current_iter = 0\n",
    "\n",
    "while epoch < niter: \n",
    "    epoch, trainA, trainB = next(train_batch)        \n",
    "    errD,  = netD_train([trainA, trainB])\n",
    "    errD_sum += errD\n",
    "    \n",
    "    errG, errL1 = netG_train([trainA, trainB])\n",
    "    errG_sum += errG\n",
    "    errL1_sum += errL1\n",
    "    \n",
    "    for i in range(3):        \n",
    "        _, trainA1, trainB1 = next(train_batch)\n",
    "        errG, errL1 = netG_train([trainA1, trainB1])\n",
    "        errG_sum += errG\n",
    "        errL1_sum += errL1\n",
    "    \n",
    "    gen_iterations += 1\n",
    "    if gen_iterations % display_iters == 0:\n",
    "        if gen_iterations % (5*display_iters) == 0:\n",
    "            clear_output()\n",
    "        print(f'[{epoch}/{niter}][{gen_iterations}] Loss_D: {errD_sum/display_iters} ' + \n",
    "              f'Loss_G: {errG_sum/(display_iters*4)} loss_L1: {errL1_sum/(display_iters*4)}')\n",
    "        \n",
    "        _, valA, valB = train_batch.send(6) \n",
    "        fakeB = netG_gen(valA)\n",
    "        showX([valA, valB, fakeB], gen_iterations)\n",
    "        \n",
    "        errL1_sum = errG_sum = errD_sum = 0\n",
    "        _, valA, valB = next(val_batch)\n",
    "        fakeB = netG_gen(valA)\n",
    "        showX([valA, valB, fakeB], gen_iterations)\n",
    "        \n",
    "    if epoch > current_iter:\n",
    "        current_iter += 1\n",
    "        \n",
    "        if not os.path.exists('weights/100L1_128channel_4gen/generator/'):\n",
    "            os.makedirs('weights/100L1_128channel_4gen/generator/')\n",
    "        if not os.path.exists('weights/100L1_128channel_4gen/discriminator/'):\n",
    "            os.makedirs('weights/100L1_128channel_4gen/discriminator/')\n",
    "        \n",
    "        netG.save(f'./weights/100L1_128channel_4gen/generator/epoch_{epoch}.hdf5')\n",
    "        netD.save(f'./weights/100L1_128channel_4gen/discriminator/epoch_{epoch}.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab13/.local/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# Here I trained three models based on different parameters, used here as appropriate\n",
    "# generator = load_model('weights/GAN/100L1_128channel_peisenet/generator/epoch_2.hdf5')\n",
    "# generator1 = load_model('weights/GAN/100L1_128channel_4gen/generator/epoch_10.hdf5')\n",
    "# generator2 = load_model('weights/GAN/1000L1_256channel/generator/epoch_10.hdf5')\n",
    "\n",
    "generator = load_model('weights/100L1_128channel_4gen/generator/epoch_1.hdf5')\n",
    "generator1 = load_model('weights/100L1_128channel_4gen/generator/epoch_2.hdf5')\n",
    "generator2 = load_model('weights/100L1_128channel_4gen/generator/epoch_3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in generator.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACUklEQVR4nO3cO2sUURjH4f9sEhHxAiIoJniLCAoGL52CiBcsBBsLCwv9DnaCpeAnEEyRysLCQrG1sLY0XRAVTREk0YiaGNfkWEQ7ETzFEeV52i3e2bPvLPwYmK6UEgAAAP5M729fAAAAwL9ITAEAAFQQUwAAABXEFAAAQAUxBQAAUGHwdx+OjRxo9qq/UkqGBnvZumVduq5rNnPTuqEc3Lm+6cwdu7fn+KmjTeb9nLlxZF827x5rNvOngaHtbQ72h67r/vvXU45u25yrp4+m13Bnd44O59jJI03mJUmv6zJ+73Fu3XmY1j9oKaXpzibJxKObTb/mt4WlzD19kbK80uy/L/1+uk8f0+pwSykZ3bstZ88dajRx1czcfF7PzLY71yRv3yzl8o3xpnv75P5E050tX/pZnppJVlaSRmc7vzCfyenJJrOS1Z3dt384Z84fbjYzKXmfDZnNpmb3ZpK8ezmdC5euNd3Zuw9uN93ZlcWvWXr2Kllut7P9r4v5MPumyaxkdWd37dmaE6cPNpuZlCz21uTzwNpWx5okeT41l4tXrv9yoidTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFBBTAEAAFQQUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFBBTAEAAFQQUwAAABXEFAAAQIWulPK3rwEAAOCf48kUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFDhO7Vud0MDWXbGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACOUlEQVR4nO3cv2oUURTA4TOzmzVu4ho0IC6baBAE/wVBUFSIGMTOJmksTCf22vkGFnZW+gS29r6BTyCiKROESDBFYmGujduJ4CluiHxfu8UZZs9e9sfANKWUAAAA4N+0B30BAAAAh5GYAgAASBBTAAAACWIKAAAgQUwBAAAkdP/24eLoYrVX/ZVSYqLbxqnZfjRNU23m8f5EXDkzXXXm/MIwbi9fqzJvPHMwOh8nFharzRzrTAzr3Njf/vedjYj4trMTHz59jP2Kb+JcuX89Xj5/FLVGtk0Tb96+jxev30Xt942WUqrubETErQtLVfe212tjfm4y2rbeuTecG8Tq2uWqZ+1050ic7h2LiHpf6db37djc3qp6Jmx+/hErT19V3du7N+5V3NmIThsx6EfUuq2llDg3OhlPVm9GW21nI7pHm5icaaLezpbYK/3YjamKv5KIjfWNWH74rOrOLl26cwD/D3pVz7zh2ZlYeXw1mlpne5SY2u/E7M9elXnjqXvRj912uurOrn/5Gg/W/ryznkwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASGhKKQd9DQAAAIeOJ1MAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEn4BNA1rQwK1sjwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACU0lEQVR4nO3cv0vUcRzH8ff3foR3aUFEP1Q07ZdICtVUDUUcErQ09Ee0BdEQbS0VBe21tLa211I0NEZNQjgFDU1peuWPb0O6RdB7+IjweKw3vO+OF8LTg29V13UAAADwfxrb/QYAAAB2IjEFAACQIKYAAAASxBQAAECCmAIAAEho/evF2dHpYo/6q+s62q1GHNzfjaqqit3c223HzPhg0ZtjE8Nx4fLZIve2bu4ZPRH7JmaL3dzSbA+X+WI3VVVV9PGUQ51OnJuajmajzP8l6rqOvbvbMTNWdrPjR0fi/KUzRe5FRDSqKp69eBUPn76M0s8breu66GYjIu48vln0Y/5a7MfC6/nYWNsosqM/u23FzESn6G4njx2K3lzZv3vLaz9icfV7sc8ZETH/sR9Xbzwputt3D+4X3ey3xaV4/uZ9rK6vF9psxFCnipOHm0U3e3xqJHpXThe5t3k1+lU3lhuDUXCy8eXz1+hdv1V0s4/u3S262ZWllfj09kOsF9tsHUPdZkyNDxTd7JHJA3Gxd6rIvc2jsbqrFT8H2lFyQAsL/Zi7dvuvJ/0yBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACChqut6u98DAADAjuOXKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJvwFuOnVDYyll6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACNklEQVR4nO3cPW9OcRjH8d/pkbuNeogSYUF0MBgxGCwSgxiYzCaJeAtG4R1YxGCTiFHiHRjsxNKFiNBq0qjbQ+uysInEP/GXJp/Peg/XOcl1Hr45yT1UVQAAAPg7M//7AAAAALYiMQUAANBATAEAADQQUwAAAA3EFAAAQINtf/rx4cK5bn/1V1WZ2z6b4yeOZhz7NF5VZXJ0Txaun8owM3SZmSQfptMsraxkGPrNXFpdy/Pl1a4zk+TWlZtdB/bc2SR5vbmeG2vP8ikbPcfyD1VV34skydPFS/32tpK1uc08PraejTHpcbJVlYUD8zl94Ui/e1BVahyTyWyfeT8tv1rN26X33c6zUtn1eS7Xbj/ourdP9p/tuLOV6fxMXp7cnu/j0G1nd+6bZPHMnnR7bFZlY24+X3fv7XKOv4xfvmWcfu34flBZf/8xl6/e6bqzjw6d73qfzWQz4+FPGXp9tqjK5sFJphcXkl7vtFUZxh0ZZg903dl3K5U3b6vftZlk+cW73L13/7cTfZkCAABoIKYAAAAaiCkAAIAGYgoAAKCBmAIAAGggpgAAABqIKQAAgAZiCgAAoIGYAgAAaCCmAAAAGogpAACABmIKAACggZgCAABoIKYAAAAaiCkAAIAGYgoAAKCBmAIAAGggpgAAABqIKQAAgAZiCgAAoIGYAgAAaCCmAAAAGgxV9b+PAQAAYMvxZQoAAKCBmAIAAGggpgAAABqIKQAAgAZiCgAAoIGYAgAAaPADllpvQ+CmRbgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACNklEQVR4nO3cMY9MURjH4f+ZsbO7s7bYFVFpttVIkPgCkq2pqIRSQSUKOpQSEnwBGqKn1SspCInIViyJRij2VUkUInESRyTP007x3nNz5tz8cpPbqioAAAD8mcm/vgAAAID/kZgCAADoIKYAAAA6iCkAAIAOYgoAAKDDrt/9+HD92LBP/VVVluaLOXBoI9PpmMarqsw21rJ+7kjapA2ZmSQfv3zJm+3ttDZu5ptPn/Piw6ehM5Pk+umrQwe21nye8i/Y3DyaK5fPZNTXPyeTlvv3n+T2nUdD5v2sqsb+SZKcv3Rh6Fk7X17I4YP7Mp2OWWpVMp/uZP/yt4w6gqoq06WlLK6tJhk0tCVvn73Lq6evhz1TqpLds0lO3ro3dN8+vntz8FlbmaSG7p/Z4iTre2bjnpuVtJWWtqeljdqzqWx/m+X919mwe5skO++2cuLUxaF79sGNawPP2WQ6rays7oy7r1Vp811Z2D8ftmcryUKS5dYyaqGVSmUt1fYOmffD1vOXOX72/C8X6c0UAABABzEFAADQQUwBAAB0EFMAAAAdxBQAAEAHMQUAANBBTAEAAHQQUwAAAB3EFAAAQAcxBQAA0EFMAQAAdBBTAAAAHcQUAABABzEFAADQQUwBAAB0EFMAAAAdxBQAAEAHMQUAANBBTAEAAHQQUwAAAB3EFAAAQAcxBQAA0KFV1b++BgAAgP+ON1MAAAAdxBQAAEAHMQUAANBBTAEAAHQQUwAAAB3EFAAAQIfvgDFjQ89BvyIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACSklEQVR4nO3cv29NYRzH8c+5t9qrfkRbCWlMDI1YJGIUlq5sBgNGUYPNahCW+gusNon4B6ySxkzC0EEjJFrViqLV+/gHROKJPI14vdY7fE/u/Z4n952TnK6UEgAAAP5Mb6cvAAAA4F8kpgAAACqIKQAAgApiCgAAoIKYAgAAqDDyuw8fTc42e9VfKSWD8bGcOHU0/X6bxiulZPToRCbnTqfrdU1mJsnHr1+zuLKSrms3c3F1PS+XV5vOTJK7V+80Hdh1XdPXUx7ffzCPz17MoP/bW+mvWlh+m8vPnmRzuN1s5v+klNL2Jkkye/Zc07N2emSQ+amZjHX9RkOT1alhnp/ZThp9u6WUjO0dZO/hiVYjkyRfPn3O+vJaw7O2ZH1pO9duPWi6t09vXG+3s0l2fyuZeV3SG6bNDpVkbbrLi/O7kla/ZSnZ2ncg3w4dabezpWSzDPN9OGw2syQZffMhVy7dbrqzD+duNt3Z8a2Sk++SfsOd3Zz+kbULG+0elZSSzdHJbOw51vScXd7o5f3nXtP/tEsLrzJ/7/4vB3oyBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFBBTAEAAFQQUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFBBTAEAAFToSik7fQ0AAAD/HE+mAAAAKogpAACACmIKAACggpgCAACoIKYAAAAqiCkAAIAKPwEheXdDXYslSQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACJklEQVR4nO3cvWpUURSG4e/MTCaJozGGBEPiDxgSUEHEQk1jYyeCjTZ2Fl6HeAWWlpZej6ViJSgqBKugILptUliI4AJ3CDxPO8U6wyz2OS8HZmitBQAAgH8zOuwLAAAAOIrEFAAAQIGYAgAAKBBTAAAABWIKAACgYPK3D08OQ7e/+mtJFhaOZ2d7N6PRuM/M1rK+spS7Ny9nGIZOM5PZ7GNW114l6TWz5ez6+Wyd2+4y73fDtad9vuSBnjubJD+S7PccyH/XWuu6s0ny4Or1fmdta5lMJ1neXM4w6ncGrW3McvveVreZSUtG42QyTafjPUny7d1evr793O+ekmSuDbnz5GXXvd3d2O66s7MTx3Lj1pWMx/2eD5ZWprl0faXbb5nWMswvZpgtd9vZluTUl69Z3dtPz6Hff+7n4uNnXXf2yuaFrjt7amGahzubmRv1eW/RWst4Yz6L9093fKZtmYyXMj8902XewdSMPrWM37euZ/uHN6/z6PmLP070ZgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAwdBaO+xrAAAAOHK8mQIAACgQUwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQ8AtKk1hD+b7psAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACPklEQVR4nO3cP0tWYRzH4e9RM/XxT5qKZH+GMIqGoMlqCKKgoKGCoCUoehUNDW1BY2+gF1RDtEZjSaggPBVoj3dDFA0RdA+3SNe1nuF3Dvw43B8OnK6UEgAAAP7N0F7fAAAAwH4kpgAAACqIKQAAgApiCgAAoIKYAgAAqDDyt4szXdfsV38lydjYZE6tXMjQ0HCbmaVkaW46N1fPpuu6RjOTXm8t8wtvkrSaWXJs6UROHl9pMu933fmnbR7y57yGO5skvbGpnFtZzXCjnU2Srf5m3r5/lVJ2m838n5RSmu5skty+cq3d3paSbmgkI6MzDd97JYcXR3Pp6nzTmZO9A1lanGgy75eNreTTZtLoOZNk7WNy68nLpnv77N6jpu/az9vf8vrDega7pckOlVKyuDyRy3eONt3Z3sR4FuZmm8xLfpy9el93MvVlp9nOlpL0+/1cfPC86c7ev/Gw6c4Odgfpb/ebzSulZOrIeM7cXW66s/PjB3N6tpdmZ9qUTG8Mcmht0GpkkuTd2nquP37xx4m+TAEAAFQQUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFBBTAEAAFQQUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVulLKXt8DAADAvuPLFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQ4TuPampDLsF1hQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACP0lEQVR4nO3cv0vUcRzH8ddXg0SlLH+kqeevsyWnphr6D/oDmvorpDWClua21mjwP2mtaGsJClMKgpQy9T4NOThE0Gf4iPB4rDe87rg3xz05uK6UEgAAAP7P0Fk/AQAAgPNITAEAAFQQUwAAABXEFAAAQAUxBQAAUOHCvx683HXN/uqvJBkZGc+N9TsZGhpus1lKZq9eyr3bN9N1XaPNZGzsc6amXydptVmyOLuUtd56k73TuluP27zIEy1vNkmOk+y3HExyc3k1m/cfZKjpzW5navpNmt7s3HLWFvtN9k5rfbNJ8nLradO7/XV4lA+fvmUwKGlxRiUlF38OZ2ZnJF2zG0pGr+xmavVtWt5tb34+/ZWVJnsnq9n5OprFu4+a3u2rrRdNb/bweJCdvYOUtHo3k8PvB9l//6XR2p+bHZ/czky/7WftwvxCVnrLTfZORrM3mMvkxmbTm332/EnT77TDg5Lxg6Nm95ok+VGSj4Nmm6UkIxO7mei9S9PP2d719NeWmuydjGb/6FomNh7+9UX6ZQoAAKCCmAIAAKggpgAAACqIKQAAgApiCgAAoIKYAgAAqCCmAAAAKogpAACACmIKAACggpgCAACoIKYAAAAqiCkAAIAKYgoAAKCCmAIAAKggpgAAACqIKQAAgApiCgAAoIKYAgAAqCCmAAAAKogpAACACmIKAACggpgCAACo0JVSzvo5AAAAnDt+mQIAAKggpgAAACqIKQAAgApiCgAAoIKYAgAAqCCmAAAAKvwGcDxxQxKWLlIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACOUlEQVR4nO3csWoUURSA4TOT3bhZswRFBKNgYSQiaiF2lnZWgoWQRp9BGy0sLKxULAQVERubNFb6ClpbG5BIEIJhAzFRE8G9thYieIobEr6v3eLMzN6Z2X8HpimlBAAAAP+n3e4NAAAA2InEFAAAQIKYAgAASBBTAAAACWIKAAAgofOvD589vF3tVX+llOj2xmL65FS0bVNt5sTUeBw6cyCaSjMjSmxGL9ZjEBH19nN61I+jo0GliX/onqo6smmaXf96yvMXTseLN7ei7dX5L6SJJl6/fBs3rj2K0WjXH94opVQ/Ta5cvlr1Wju1rx+X5s5FpzNWbeZgshsnZgfRNPUO74/hRgw/fKk6c/n9p1h6t1BtZiklevsnY+75fNV1++rB/aprtu11Y/z4wWr36lJKDAadmJntV10/31e3YvXjt6ozY2U9YnktouLMlc2vcfHm3apr9vG9O3V/0/b3xOGzM9GO1blXlxKxd+JXHDuyVfOrjJ9rTWwstVXX7NrnYQwXl6vOXFhcietPnv51oCdTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABKaUsp2bwMAAMCO48kUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgITf8o9tQyihtbwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACV0lEQVR4nO3dMWtTURzG4femTdoKtSA6WBBBNxHxgzgorg7uQpdugpuTi4KgKLg4OTm79EPo5iB1EIdqRWtrNG1zHFwcROiBHDF9njXDP5ece+DHSW66UkoAAAA4mN6/fgMAAAD/IzEFAABQQUwBAABUEFMAAAAVxBQAAECF2b+9+PjurWaP+iulpD8/k+VzS+n1umYzF5YGOXnheLpGM5OS75nP1ywmaXedy+MjOT1ebDTxN/3zTUd2Xdf08ZRnzi7n3sOVzM0Nms189fJNbq4+yu7uXrOZh0kppfltcu3S1aZ77bETC7m+cjH9wUyrsdkdJVtfujTb95LMduMsdKXVyCTJt7cb2X79Pl3XbuholFy+87Tpun2x9qzhmk1mZ3azdPRDfm3xLS61ZG80k+GnuaTRZ1mS9Lf3s7AxajYzpWRYxtkZ77e7TUoy3NvKldXbTdfsk7XnTdfsoDfKqfn19LpxWq3ZrgzSz1K6lpvecJRsbjfd84afR9nZ/NF05vq7j7lx/8EfBzqZAgAAqCCmAAAAKogpAACACmIKgKnU/MdvABw6YgqAqdT0aTQAHEpiCoCp5GQKgEkTUwBMJSdTAEyamAJgKjmZAmDSxBQAAEAFMQXAVPI1PwAmTUwBAABUEFMAAAAVxBQAU8kDKACYNDEFwFTymykAJk1MAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFChK8XfGgIAAByUkykAAIAKYgoAAKCCmAIAAKggpgAAACqIKQAAgApiCgAAoMJPRlx2Q4td26EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACLUlEQVR4nO3cQUtUURjH4f8dddRxJifKMkdyEVKE1iYoatmnahG5adEq3EYk9Bn6ThEVUWlqwZwWFbSIoLM4YjzPdhbvvfDO4f7mwnSllAAAAPBveid9AQAAAKeRmAIAAKggpgAAACqIKQAAgApiCgAAoMLs3z589vRhs7/6K6VkbmEma9eX0+t1zWYuLvdz6cb5dI1mJiVHWcjnjJK0u8+16SAb01Gjib+Z22o6suXOJsnrN+/yZHcvh0fHzWbeu7+dF68epLfQ6reQk9rZpWxMh//9zibJ3uOdpmftbL+flY31dL02O1RKydLZuVy5NUzXtTtrv5T5vM8wXcO9vTgdZH06ajLvl3cf3mb16p2me/t8p+3zwXAwzO2tu5mZmWk0NMmZb8m1/VbHXpKS4yzmoBs3m1lSslIGWS3DNgN/Ojj8lPFku+nOvtx91PaZdr6fyeYkvYbnbH84m3Obi03P2a9lIQdludnXpKTkQkaZdONGE3/Y3/+Y8eWbf7xNb6YAAAAqiCkAAIAKYgoAAKCCmAIAAKggpgAAACqIKQAAgApiCgAAoIKYAgAAqCCmAAAAKogpAACACmIKAACggpgCAACoIKYAAAAqiCkAAIAKYgoAAKCCmAIAAKggpgAAACqIKQAAgApiCgAAoIKYAgAAqCCmAAAAKogpAACACl0p5aSvAQAA4NTxZgoAAKCCmAIAAKggpgAAACqIKQAAgApiCgAAoIKYAgAAqPAddnprQxIgXKYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAChElEQVR4nO3cv0tVYRjA8edkUnkhakiIKIIo7LdEURJkJVFgbkJL4dLa0Nr/0ZjQFC5NDRFIFAgNJUZEIBEiQdcgchAVf5zTUE2J4Eu9lxOfz3qHc9/Lc1/Ol8N5i6qqAgAAgI3Z1OovAAAAUEdiCgAAIIGYAgAASCCmAAAAEogpAACABJvX+/D18L28R/0tLUd8nokoy4ii+PfXqyLKbVWs7K4iMlzutw9Ts/H4xXQUOdYYEVVZRldvT3QPXInIfHrjrXM3Mv6yEUVRZF3gwc6dMTx0Nba2r/tX+qvGp2fizqPRWFots11zT+eO6O7am+16VVnG4Uvn42R/338/sxERI/fvZltkFREdyytxqjkbbWXk2fuqKha3b4nmsV159vZfPn76Fk9HJzPutVUc6j0Rx6+f/flDZ1I2F2Kw73bWuR1/9jDrzLbNz0XHxFgUq6uZ7g+qKNs7YrWxL+vMTnxpxsjbd1nvD4709UT3wOVse20VEY3FxRg4PZh1Zl+NPcg7s3Pz0Xj5JoqVfDO70tgS8/s7s87s5NTXePL8fdaZPXDhTBztv5h1ZsvvCzF07eaai/RkCgAAIIGYAgAASCCmAAAAEogpqKG8bxEBALAWMQU1lP2EBAAA/iCmAAAAEogpAACABGIKAAAggZgCAABIIKYAAAASiCmoIUejAwC0npiCGnI0OgBA64kpAACABGIKAAAggZgCAABIIKaghhxAAQDQemIKasgBFAAArSemAAAAEogpAACABGIKasg7UwAArSemoIa8MwUA0HpiCmrIkykAgNYrqsptGQAAwEZ5MgUAAJBATAEAACQQUwAAAAnEFAAAQAIxBQAAkEBMAQAAJPgB2QuNQoxhP5kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACTUlEQVR4nO3cTYtPYRjH8d8ZM8xEaspDs9IosqAsKWWlKaWUhZUUb2GyQMl2drbU7Gy9AaWspNgpG+UhUxg1ZMw0T+e2MHaacsc9TT6f7X9xnXO6zun/7dTpSikBAADgzwxs9gEAAABsRWIKAACggpgCAACoIKYAAAAqiCkAAIAKgxv9+Gz6ettP/S2vJO8/Jn2fdN2/n1eSfqRkdawkDcb98vLNlzx4/C5di3NMUvo+R06fzPFzZ5LGX2+8dOJiwyubdF3X9AQP7RvN9OWJDA9teCv9PZuws12XPHz6JrfvPUn/H3z9s5TSdGeT5OzE+WYXtpSS/Tu25cb4rmwfaHSqJVnZ3Wf+6HK7Z20pWds5mtU9BxsN/Glhbj7fZr82e74nyezbxVy5ebfp3j66dqvdziYZylL2dq/TdX2aLFFJ1kb6LI213dnl0fEsHDjVbmSSfmEl/fflNv+71mfOf5jJhas3mu7s/cnJpjs7nNUcHpzNQFfSamdXR/osNtzZUkoGR/dl+OCxNgPXfZormflcWq1skuTF81eZmrrz24neTAEAAFQQUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFBBTAEAAFQQUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVulLKZh8DAADAluPNFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQ4Qf58IBD6gHKhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACHUlEQVR4nO3cu2oVURiG4W92Du4kkmNlZyPaCClNoRZiGRQLg4qIpV6CV2Eh2OkdWAtW9va2IhbaCR4wMc6ySieCP7hCwvO0U6yZvRf/8DKwhtZaAAAA+DeTw74BAACAo0hMAQAAFIgpAACAAjEFAABQIKYAAAAKZv928c2zR32P+tv7mXz4lIxjMgz/f72WjAst+6da0mG5A2/ffc6L1+8z9HjGJG0cc+7yVja3ryadT2+8e2Gn4y+bDMPgeMpjYvve9dx8eCttPN57Nkke7Nzp9pCttSxOZ7N5djUzM51mUGtZOjmX02fWu4z2A+MwyTgz2+d9kiStZXd5OT9W13u+UtI+fs2Vi/e77tuXTx93nrUt6ftXZn42WVtK10X3FhfzfW2j3/5pyd6JSXYXJhk6rdrSstLGXDp/o+ueffX8Scc5m0wmY6bT/X4zryVtfkjbmOu3Z9OyP0yzO6x0nO0t3yZjvkx+dZ0Hq+OQa1u3/7iiL1MAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACobW2mHfAwAAwJHjyxQAAECBmAIAACgQUwAAAAViCgAAoEBMAQAAFIgpAACAgt9GumJDQbF/qwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACP0lEQVR4nO3cu2oVURiG4W+yd0RGtxGxSCwSOy0koIgiiIKolV6BhYfCRq9ArMTCS7C0Eo9FQLQQ7G3NPRgMHkAl6k6ylzcggqtYEniedop/ip/FvDMwXSklAAAA/Jup/30DAAAAW5GYAgAAqCCmAAAAKogpAACACmIKAACgwvBvFx/fuNvsV3+llIz6Yc4d3pNtg67R0GTSj7Ox8DlpNDKlZHV6Lsv9kWYjk+TdWvL2e9K1HJrk2bGjTSe23tld/TBnW+/sjnE25tvtbNclD18t59qt55lM2v3988CVqzl042YymTSbmbTf2SR5dPl2073d2U/n9NHZDAeN3qeVpMz8Sln82O6sTcm39e1ZWZtpdu51KXnTzWapm89UuyMh+z+s5sH5C0339smlO22fD0bDnDyzO4OGZ23Z8SNlYaXpzq5vzmVtY7HZyC4lL6dGeTqYabuzXz/l/olTTXf2xfV7TXe27wc5frhvurObo3HGBxs+06bkZ9mVL9nXdGdfr+/Ns/Fc053d/X41SxfP/3GiL1MAAAAVxBQAAEAFMQUAAFBBTAEAAFQQUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFBBTAEAAFQQUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABAha6U8r/vAQAAYMvxZQoAAKCCmAIAAKggpgAAACqIKQAAgApiCgAAoIKYAgAAqPAboG53Q0PBHiAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACQklEQVR4nO3cz4tNYQDG8efce0czd2ZMSJryIyV78mPBFCGKZmFvo6ysrSyksLOwVP4BhZpSFpSNDTsslKUFMhk1TdfMdMfxD0h5F+80+Xy2d/GexdPpfO+p07RtGwAAAP5NZ70vAAAAYCMSUwAAAAXEFAAAQAExBQAAUEBMAQAAFOj97ceHV29V+9Rf27aZ7Pdy5sDWbOo2lQ5NfvVXM9yzkFQ6Mm2bbyPTed8/WO3IJHk3SF4vJU3NQ5M8OnKo6om1N7u538vpmptN8uLDx1y4cy8rw2G1M09dPJ9rd2+m5tc/3w6SN//BZpNk7vL1qrsdnxjJsZnpdLuV/k9rk5XRtczvWK56r10b35aV7furHdkkebnYZO5Hk06l4bZJds9/zYNzs1V3+/jSjbrPB5O9HD85lW6154M2a2P9rE7vrHcTatssjo7ly9RU1c2+Wu7k+c9u1c3uWpjP/ZkTVTf79Mrtqpvt97s5fHRz1c0OJ7pZ2jdadbODkS35Pra37mYHybOlJp16uZCJT5/zZPbsH0/0ZgoAAKCAmAIAACggpgAAAAqIKQAAgAJiCgAAoICYAgAAKCCmAAAACogpAACAAmIKAACggJgCAAAoIKYAAAAKiCkAAIACYgoAAKCAmAIAACggpgAAAAqIKQAAgAJiCgAAoICYAgAAKCCmAAAACogpAACAAmIKAACggJgCAAAo0LRtu97XAAAAsOF4MwUAAFBATAEAABQQUwAAAAXEFAAAQAExBQAAUEBMAQAAFPgNiKF0Q4No5zEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACKUlEQVR4nO3csWoVURSG0X/MNdFoQA2CVsFHUMTGUmxsfIBUWgnWNoKVqfIG1toIog9gbWGrlSBYSIhojIoxJJdktpWdCB7wBGGt9hZ7ij3D+WbgDlUVAAAA/s6hg74AAACA/5GYAgAAaCCmAAAAGogpAACABmIKAACgweRPPz6+vdLtr/6qKgvzk1w9fyqzM0Onock4P83e0mbSaWSq8vHw2byev9BtZJK82k5ebiVDz6FJnly62HViz51NkrXNT7n39EG2p7s9x/IPVVXnuyR5cafv3n7f383zrbfZy5ihw5OoqrJ4ej6Xryxl6PgQGpIcGtJ15td3G9l4s95vZlUyHsmN1Ydd9/bZzbv9drYqdXIue9fPJZM+74ArydHpNGe+felyj/wy7lX2d9L1TLK7P2Z3f+w3Msk4/ZFrt1a67uyj5X47W1WZOT7JsSsnMsx02tlKZmYrs4tjt7NepTKpucxlIb2WtpKMn3cyftjueqhde7+e5furvx3oyxQAAEADMQUAANBATAEAADQQUwAAAA3EFAAAQAMxBQAA0EBMAQAANBBTAAAADcQUAABAAzEFAADQQEwBAAA0EFMAAAANxBQAAEADMQUAANBATAEAADQQUwAAAA3EFAAAQAMxBQAA0EBMAQAANBBTAAAADcQUAABAAzEFAADQYKiqg74GAACA/44vUwAAAA3EFAAAQAMxBQAA0EBMAQAANBBTAAAADcQUAABAg580GnVD7YfK0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACK0lEQVR4nO3csWoUURTH4f9sko3BZDchITFGEtRoISjaWOsb2PgKYpFKBFtbWwtfwEcIgo9kI4ikCJjstYh2InggN0S+r93izLCHy/wYmKG1FgAAAP7N6KIvAAAA4DISUwAAAAViCgAAoEBMAQAAFIgpAACAgvm//Xh466Dfp/5a8n3xRw7vfsnJaJYhw/mPbC2LG9NsPnmQYTj/eb+G5mR9O8f7jzrc4ZlZa3k8P8nThdX0/nbjnd1pr9tMkgzD4POU/4mXB6/y+s3bzGazrnN772ySvHj+rNvetpaM54fsrS9k1Onca61lZXUp9x7udDtrW2sZT6ZZ3rnRZd7vmZPJbtZW97vNTJKjb19zfe9+17399OFd1+eDjJLR0lzH/UnGc8lkMen1eJDWcrK8kuPNa92eD1pr2ZjsZGu622ni2d/Z2lG2tm933dnPH993PWfnRi3LS6dd92c2HuVkOu65tJmNruR0bi29lra1ltWr21mf9NvZJBmG49zc3f/jXXozBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBATAEAABSIKQAAgAIxBQAAUCCmAAAACsQUAABAgZgCAAAoEFMAAAAFYgoAAKBgaK1d9DUAAABcOt5MAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACj4CaLxWkNo6RZcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACTElEQVR4nO3cPUuVYRjA8evx7eTxNTXTLAPJE0EFLk4V2VJLzUFjS4NTCBEU9FH6CmHfoKFob2hrKzCpHFLSzt1QbhF0gbcIv996huu5Dxc3/HngaUopAQAAwP/pOewHAAAAOIrEFAAAQIKYAgAASBBTAAAACWIKAAAgoe9fP64vrNb71F+J2GrtxnrnU+z1dKOJ5uBHlhKtqbGYvn45mubg5/0ZGnuTs7FzbqnCCX/rlhLLfaOx0j8etb/duDg/VuuYERHRNE3VI46NjsaNa1eit7e32syNz5vx6vWb6Ha71WYehgerD2Pt0bPq56y9sxER92/drHjXloi+nuiZGKx275VSYmqyHStXz1adOTQ8GNMzx6vM25/ZHlmMofGL1WZGRHzZ3IiFzlLVvX3x5GnVu/br9na8fP8u9rrdKjtUSon5UxNx7/Zy1Z3tGx6J1omTVebtz2wPzcbwyJlqMyMidne3Yu50p+rOPl97XHVnv+/+iLcfP8TPijs7MzcWd+5eqrqzAwPD0W7X3dlW/2wca81XmxkRsbPzLc53Lvz1j/VmCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAEBCU0o57GcAAAA4cryZAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJDwC6BlcEOha8buAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACT0lEQVR4nO3cz0pUcRjH4XemGUdNNBipTFAMzYgKIyyyFtom2kiX0ELo73W06B5aBu0lqBZtIuwWIog2QTBaUhihw5wWtYygF/yJ9DzbWfzOgS+H82Hg1KqqCgAAAP5Nfa8vAAAAYD8SUwAAAAliCgAAIEFMAQAAJIgpAACAhMbfflw9fr/cp/6qiK+tnVg98Sm69V7Uorb7R1ZVtEZH4vDi2ajVdv+834dGtz0WP6bPFbjDX3pVFRcaw7HUPBSlv904MzFS6jYjovxmN/t34ulMuc1GRHTWN+LV2pvo9XpFzouImLmxHEsPH0QU+vpnr6riYmM4Fv+DzUZErM2vFN3t58Z2PGp/jJ1auWft1ORI3F2Zi3q93LP2fetYvBw6H6Ue772qisvNgbjWd7DobjvrnZicnS+629enbhbd7MZANx7PdqJbr4ptdnp8NO4tXyq62beDR+N5+3TR94OFZn9c7Rssutmt75sxPnmy6GZfnLlV9v2guR1Pjnwo+k47NdWO23cWim723YGxeNaaK7rZK43BuN4cKrrZb1tfYmJm9o+36Z8pAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAliCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEgQUwAAAAm1qqr2+hoAAAD2Hf9MAQAAJIgpAACABDEFAACQIKYAAAASxBQAAECCmAIAAEj4CV6zgUPi8o5EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 7 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACQ0lEQVR4nO3cu2oVURSA4TXn5ORcPIm5iUGiYFBLiySomIiKYvQpVFTwYSwt7UTwGezE1sbSThTBQhGMIRdJtoXYScCF7BD5vnaKPRvWbOZnYJpSSgAAAPB3Wvt9AwAAAAeRmAIAAEgQUwAAAAliCgAAIEFMAQAAJIzsdXG2M1/vV3+lxO6wH9sXz0a029XWjMl+NEvHo2maSkuWON3rxM2xQUSdJWO3lFgYjMbKsBe1/9149Pr9Srv8pWmaqltsjU/EcPlGNO09H6V/p5SIqUE0i3NVZ/ZMrxOrlWd2cdCN5WH3v5/ZiIjPLx9V3eaHL5vx4Mnb2PyxU2eOSomdmX5sXz4WUW1uI051W7E6NlJtzd1SYmF8GCuTh6us99unb1tx4trDqnO79ux51Zl9t7Yed1+9jq2dijM7NRob56bqzWyUONkaiUsjo1XP2gvTvbh6pF/trC2lxPfdfswu3ak6sx9fPK46s++/bsTtp2+qnrPNzKFoXZmv934QEXOtJs6321XP2ZWJTtyarvl+UGK96cbM8r0/btKXKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJYgoAACBBTAEAACSIKQAAgAQxBQAAkCCmAAAAEsQUAABAgpgCAABIEFMAAAAJTSllv+8BAADgwPFlCgAAIEFMAQAAJIgpAACABDEFAACQIKYAAAASxBQAAEDCT+4sb0PmKoMBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACPklEQVR4nO3cu2pUURiG4X/NZDKTnUSIiXiMh5ADCopoMBhjERS1EKzsLO1t0ngNgpdhZZdWLCwsvAaxEAWrYGEVYpaFjYUI/sUKgedpp1h7mI9h3tmwS601AAAA+D+9g74AAACAw0hMAQAAJIgpAACABDEFAACQIKYAAAASxv714onBQrtH/dUa+1MTsbt+JaLfb3ZmzExEWZ2PUkqjI2ssjQbxYLqLaHNk7Nca17rx2JgaRetnNx6/+7TRu/yt/Wa72F2/3HazR7so18803ezyaBD3G262lBLvt9/Gm1fbbQ78Q6216WYjIrYWNpvu9sdwEO+WT8XPXq/NR1prxNwoyubJhruNWBkv8XCyRKvh1hpxaSZi9Vjb/yk/fdiJi09eNN3ty6uPmm52ZzgWrxeOxF6vtNvsbBexNh/RarMRsdQrcWesNDtzv9ZYnZmMW3PTTX8ffPn4NRYfP2+62Run15pudm80jJ2VC1Fbfs/OdlFuN/xNGxHneiU2+v2mm715tot7i1NNN/vt8/c4v/Hsr2/SnSkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAgQUwBAAAkiCkAAIAEMQUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACaXWetDXAAAAcOi4MwUAAJAgpgAAABLEFAAAQIKYAgAASBBTAAAACWIKAAAg4RfaKWJDz6fIqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACVElEQVR4nO3cvWpUQRzG4fckGjYxEd3GCBH8bBWMCMYPCKiIpZ21io0QSKGCZe7C0la8Be/Azs4yKFoIURPRTTxjEe1EcJAJgedpt5gzy3/Pzo8DpyulBAAAgH8zttMXAAAAsBuJKQAAgApiCgAAoIKYAgAAqCCmAAAAKuz524eze4+3e9VfKemnJzNaOJ2MjzdbMwcn0507kq7rGi1ZcmqwNzdmppI2S6YvJWenJnJpepDW7248dPVuo11u67qu6RbH9h/I9MXr6cb/+lP6f0pJhlPp5ueazWy6ZPTqdTaevdhev5Gl2zfz5M6t9I3fONp6ZpPk+f3bTTf5cSt5ujaezdK1uQ2VkgwH6RZmm81tX0quDAd5cmImpdHNtpSSwY+JTP4YNFnvt3drGzl57UHTuX3zcKXpzK5ujrL8fjXfS99mhn6dDzLfdmYXh8M8Ona02X91KcmgrGey/5Jmh5Ik62Usc+fvNZ3Zl0vLTWf2w2grK28/ZdQnTUaolHTDqYxdaHem7UvJ5dnpPD4z225mk+z7/C0za18bfbHbNvouhxfv/3FBT6YAAAAqiCkAAIAKYgoAAKCCmAIAAKggpgAAACqIKQAAgApiCgAAoIKYAgAAqCCmAAAAKogpAACACmIKAACggpgCAACoIKYAAAAqiCkAAIAKYgoAAKCCmAIAAKggpgAAACqIKQAAgApiCgAAoIKYAgAAqCCmAAAAKogpAACACl0pZaevAQAAYNfxZAoAAKCCmAIAAKggpgAAACqIKQAAgApiCgAAoIKYAgAAqPAT7290Q098yFoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACQ0lEQVR4nO3cPWtUQRiG4eeIRQhR3AgigiIIKcQuYOkvyC8RsdVGrLQwvdiFdIpgL4i9WAg2ghgTJB8maIIxuNlIMlZaiZABJ7twXe0WcwZeDudmlulKKQEAAOBwjh31AwAAAIwiMQUAAFBBTAEAAFQQUwAAABXEFAAAQIXj//qxLDxse9Xf8npyfTbdoJ90bZbc7J/Mm9XLSWm0YEreZSrPMtNqi0m6fB1/lY2Jl+ka9/PK+ut228wRzOynz8mN2XSD3WYz+6KfzKwmAxdx/helNHsZ/LH7se3cHqxtpX/raTL4mXQNtltKVnoTeXx1qs16SUopmThzImevnGuy3m/ry9tZXtxM12qfKent7Ofeg7mmc/vjw6OmM1tWvuTgznyy125mv0/2sjA93WxmU0q2er0sXbzQ7vuglOyUku1Smq1ZkoytbeTuzftNZ3Zvqe17dn9tM99uzzV9zw5Oj2fj2vm2Mzs2mcVTlxp+0ybvN0vebrTbZpJkYTXPn8z/dUUnUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFYYvpprfowUAAHB4wxdTrnsGAABGwPDFlJMpAABgBAxfTAEAAIyA4Yspf/MDAABGwPDFFAAAwAgQUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFChK6Uc9TMAAACMHCdTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAECFX74RhUONueNvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACZ0lEQVR4nO3czYtNcRzH8c9FI5NYIFE2lLCc1WxIWMnWzl9godjaS9lZeFjIgqUkGztbSZLykAx5GjNDyHg4M8bMz0KspPwWP/fW67W9i+85t+899747t9MrpQQAAIB/s+h/HwAAAMAgElMAAAAVxBQAAEAFMQUAAFBBTAEAAFRY8rcXy5NTbR/192oqOXgivdku6bUZ+b5bkTuvtyWl0cCUPMzmXM6+VqeYpJd3wzfzZvn19Br38/jUrXanmfY7e3dsMjv3n8jHTzPNZo5kZY5naxY126CS+9mSK9nbdGdf5GrGcqHZxF9KaXYx+G1m/HTTvZ3tuozdu5uF+fn0em1Od/7FTL6dn2oyK0lSSh4Mbcil4dF2n5SFZM3Ih6zb/rbZd0pJsmryW44eOtt0b788P9N0Z793s5l++CRZWEga7Wz3dDoT5x79fJNbKCX3l2zK1aEdTXd27a6vWb/vc9OdXTvZ5fCBY013tnvW9vfB3Ncvmbh9o+l1tns5l4mL001mJUlKyePFG3Nt6Z6mO7ts9G2Gd0803dnV47M5eeTkHwe6MwUAAFBBTAEAAFQQUwAAABXEFAAAQAUxBQAAUKH/Yqr5c7QAAAD+Xf/FVNuHsQMAAFTpv5hyZwoAABgA/RdTAAAAA6D/Ysrf/AAAgAHQfzEFAAAwAMQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFBBTAEAAFQQUwAAABXEFAAAQAUxBQAAUEFMAQAAVOiVUv73MQAAAAwcd6YAAAAqiCkAAIAKYgoAAKCCmAIAAKggpgAAACqIKQAAgAo/AOf1j0MChhS2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACWElEQVR4nO3cu2oVQQDH4f/mYjDeukQsbBTBqGAXsPEFfBIRLMVnsBQUbC3EJqAokkaCWKgJKIqXItHgLXiLhUqiSMZOGxEy4OQc+L72FLOzDLP7Yw/TlVICAADA+gxs9AUAAAD0IzEFAABQQUwBAABUEFMAAAAVxBQAAECFoX/9WBbOtT3q7/W75PiZdN9Xkq7NkMsr23P/7URSGg2YkqfZl6kcazXFJF0+jd7N+6030zXu5zfvZttNM0nXdY6n/A925mgmciJJq9vb5WWuZj4XG433RynNNoPfrk2fbrZuSykZHhzI+I7RdF27qa5++ZalZ8+bjZeULC6OZ+bWobSaZinJyPDDbB65k1YPsVJK9u/ZldMXrjRdt9fnzrZbs0kG135mdOVjupS0uLclyfDySrbMLTV8Vpc8erE7U7cnm63ZlKQ7/CQDkw/StVqzKTkytCknT11qumZvzLZ7py1JhtZWM/7jcbqspdV+8PVzsnAvzcZLSuYXxzI9c6DpPrtt76vsOPg8zfbZJGMfPuX85am/DujLFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABAhd6LqebnaAEAAKxf78WUg60BAIA+0Hsx5csUAADQB3ovpgAAAPpA78WUv/kBAAB9oPdiCgAAoA+IKQAAgApiCgAAoIKYAgAAqCCmAAAAKogpAACACmIKAACggpgCAACoIKYAAAAqiCkAAIAKYgoAAKCCmAIAAKjQlVI2+hoAAAD6ji9TAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAECFXyNAc0OzNPxhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9 ... \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACIklEQVR4nO3cv2oUURjG4XfGuEQTd42sCgkoRhQJ2GilYEoRr0AsvQfR1sZasBIsvAyvxE5QxEotBI0QdY9FWhH8ihMSnqfd4syfMx/7Y2CG1loAAAD4P+N+HwAAAMBBJKYAAAAKxBQAAECBmAIAACgQUwAAAAVL//rxxpXtbp/6a2lZ3p1k6/1GxkWfxmtJNo4m96ZDhmHos2ZLVuZfc+byhwzps2YWLbm2nNw6vnfSPd1+3ekk9wzD4POUh8Sje5t5+uBSxkO+Z5Nk++79frO2tSxNlnLqwjzD2GvutcxnR7N9ddZv1iaZ53suD5+TjvN9dbqT6clvSa/5npYvn6bZuPOq6759+PJ55yezJWPrdllbktniV7Z+/eh4J5O1379zfne3656dnv2Y2fq79Lu4LTuTi1m7+bLrnn32+EnHOZscGReZTX72upVprWVcOZLJ5nLH/7QtK8cmma+tdlkv2XtOTo9vsz6+6fecpGUxnsuJ6y/+uqA3UwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACgQUwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKxBQAAECBmAIAACgQUwAAAAViCgAAoEBMAQAAFIgpAACAAjEFAABQIKYAAAAKhtbafh8DAADAgePNFAAAQIGYAgAAKBBTAAAABWIKAACgQEwBAAAUiCkAAICCP1HUW0PxupWxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACTUlEQVR4nO3cP0tVcRzH8c/R6/WmpSGaoFuR/aGG1CEpG1SEisgxaOyxNPUQGqq5J9DDaGipqb/QUJgNlYL+Gloj6Df8pHi91jP8zhe+3HPeHLhdKSUAAAD8naHDvgEAAIB/kZgCAACoIKYAAAAqiCkAAIAKYgoAAKBC708XV85ea/ZXfyUlg71+zr+Zz9BBm8YrSeZHkjsTXbqua3NmScand3Ji4V26tDkzByVZHCSrY7+GbmnzWaMhf2m5s0nyffdbXrx9nv2D/WZnXh2Zy+OJzQw13NmjM18yc/p9251dHiRX/v+dTZJzW7fb/daWkompQW7dO5PeyHCbM5PMvNrL2v1P6RpNWkrSn97J+MK7pOHedkujGVodNJszKfm4PZuFjSdN93bpxvWmOzs5dSQ3715Ir9fu/WD25W7WHnxuurPD89vpL75Js50tJd3F0XRLo61OTFLyNacyd/lh0529tLzSdGePTfaysXU8vV6jZ3VKZj70s/50qtmzupRkZGo7Yydfp9XOloOS/uKRjK6ON3w/KPn6Yy6z649+O6QvUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAEAFMQUAAFBBTAEAAFQQUwAAABXEFAAAQAUxBQAAUEFMAQAAVBBTAAAAFcQUAABABTEFAABQQUwBAABUEFMAAAAVxBQAAECFrpRy2PcAAADwz/FlCgAAoIKYAgAAqCCmAAAAKogpAACACmIKAACggpgCAACo8BOzTm1DIZWnLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAAkCAYAAABsd2B4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAACSElEQVR4nO3cO2tUQRjH4f/ZTTREEzBeEMRCBAlqo5UW2mlhESxUFLEQUWz9FPaCva2tlbUfwS6FQggIgngBXS8k+1qInQgOMiHwPO0p5gy8O8yPAztUVQAAAPg3o61+AQAAgO1ITAEAADQQUwAAAA3EFAAAQAMxBQAA0GDmbw/PLp/v9ld/lcrcjx05vnYoo2mfxqskh2aT64tDhmHos2Ylu/Z9yoFj6xnSZ81MKzk9l5yb/7Xpni4+77TJX4Zh6LrDvdmTK7mUmb//lP6bSnJ4NrnWcWaHJM++vc6Dzy8y7T5A/VVV15lNkjP3LnQ9a3d+HefYy/mMNof0OIYqlSPDbO6Pd2fUaW5TycdTo6zdHnc7ayuVqs1Ms9llvd+rvl2t3Lj7pOvc3np4s+9h8H6aPJ1k2Eifma3K0fFM7s3Nd53ZycmNfLj8vd/9oCqTpYV82b/Ya8UklffrlevXHned2fNXV/reab+Nc2J1oeM5mxwckpWZUbf7QSqZLk9Sl9+lyyaTpCofF/fl3dLBjjObvHlVuX/n0R+X9GUKAACggZgCAABoIKYAAAAaiCkAAIAGYgoAAKCBmAIAAGggpgAAABqIKQAAgAZiCgAAoIGYAgAAaCCmAAAAGogpAACABmIKAACggZgCAABoIKYAAAAaiCkAAIAGYgoAAKCBmAIAAGggpgAAABqIKQAAgAZiCgAAoIGYAgAAaDBU1Va/AwAAwLbjyxQAAEADMQUAANBATAEAADQQUwAAAA3EFAAAQAMxBQAA0OAnrY1sQxwEaDEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.shuffle(colors)\n",
    "# color = colors[100]\n",
    "\n",
    "for i,color in enumerate(colors[:10]):\n",
    "    print(f'Processing {i} ... ')\n",
    "\n",
    "    # color = [(212,123,80) for _ in range(8)]\n",
    "    batch = int(256 / 5)\n",
    "    for _ in range(3):\n",
    "        img = Image.new(\"RGB\",(256,1),(0,0,0))\n",
    "        im = np.array(img)\n",
    "        im_fake = np.array(img)\n",
    "        nb = random.randint(1,4)\n",
    "        index = random.sample([k for k in range(5)],nb)\n",
    "        for j, c in enumerate(color):\n",
    "            if j not in index:\n",
    "                if j == len(color)-1:\n",
    "                    im_fake[:,j*batch:,:] = c\n",
    "                else:\n",
    "                    im_fake[:,j*batch:(j+1)*batch,:] = c\n",
    "\n",
    "            if j == len(color)-1:\n",
    "                im[:,j*batch:,:] = c\n",
    "            else:\n",
    "                im[:,j*batch:(j+1)*batch,:] = c\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(15,15))\n",
    "\n",
    "        plt.subplot(1,5,1)\n",
    "        plt.imshow(np.array(Image.fromarray(im).resize((512,80))))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,5,2)\n",
    "        plt.imshow(np.array(Image.fromarray(im_fake).resize((512,80))))\n",
    "        plt.axis('off')\n",
    "\n",
    "        result = generator.predict(np.expand_dims(im_fake / 255 * 2 - 1,0))[0]\n",
    "        result1 = generator1.predict(np.expand_dims(im_fake / 255 * 2 - 1,0))[0]\n",
    "        result2 = generator2.predict(np.expand_dims(im_fake / 255 * 2 - 1,0))[0]\n",
    "        \n",
    "        for i in range(5):\n",
    "            result[:,i*batch:(i+1)*batch,:] = np.mean(result[:,i*batch:(i+1)*batch,:],1)[0]\n",
    "            result1[:,i*batch:(i+1)*batch,:] = np.mean(result1[:,i*batch:(i+1)*batch,:],1)[0]\n",
    "            result2[:,i*batch:(i+1)*batch,:] = np.mean(result2[:,i*batch:(i+1)*batch,:],1)[0]\n",
    "            \n",
    "        plt.subplot(1,5,3)\n",
    "        res = np.array(Image.fromarray(((result+1)/2*255).clip(0,255).astype('uint8')).resize((512,80)))\n",
    "        plt.imshow(res)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,5,4)\n",
    "        res1 = np.array(Image.fromarray(((result1+1)/2*255).clip(0,255).astype('uint8')).resize((512,80)))\n",
    "        plt.imshow(res1)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,5,5)\n",
    "        res2 = np.array(Image.fromarray(((result2+1)/2*255).clip(0,255).astype('uint8')).resize((512,80)))\n",
    "        plt.imshow(res2)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
